{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2eOgwG39J15b",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### load CleanLab processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "iQjLpn9zV53L",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "os.chdir('/home/xjding/personal/pythonProject/PLM4ACE_subtasks/data')\n",
    "X_new = pd.read_csv('CTDD.csv', delimiter=',',header = None,index_col= 0)\n",
    "\n",
    "# load numpy array from csv file\n",
    "from numpy import loadtxt\n",
    "import numpy as np\n",
    "# load array\n",
    "y_new = loadtxt('y_Cleaned.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "X_new"
   ],
   "metadata": {
    "id": "Ju-ijTZHK4cA",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "              1      2      3      4      5           6           7    \\\n0                                                                       \nMDFLI        40.0   40.0   40.0   40.0   40.0    0.000000    0.000000   \nMFDL         75.0   75.0   75.0   75.0   75.0    0.000000    0.000000   \nMDLA         50.0   50.0   50.0   50.0   50.0  100.000000  100.000000   \nLIVTQ       100.0  100.0  100.0  100.0  100.0   80.000000   80.000000   \nLIVT          0.0    0.0    0.0    0.0    0.0  100.000000  100.000000   \n...           ...    ...    ...    ...    ...         ...         ...   \nYAEER        60.0   60.0   60.0   80.0  100.0   20.000000   20.000000   \nYPF           0.0    0.0    0.0    0.0    0.0   33.333333   33.333333   \nYPGIA         0.0    0.0    0.0    0.0    0.0   20.000000   20.000000   \nYPIL          0.0    0.0    0.0    0.0    0.0   25.000000   25.000000   \nYRGGLEPINF   20.0   20.0   20.0   60.0   90.0   10.000000   10.000000   \n\n                   8           9           10   ...    186    187    188  \\\n0                                               ...                        \nMDFLI         0.000000    0.000000    0.000000  ...   40.0   40.0   40.0   \nMFDL          0.000000    0.000000    0.000000  ...   75.0   75.0   75.0   \nMDLA        100.000000  100.000000  100.000000  ...   50.0   50.0   50.0   \nLIVTQ        80.000000   80.000000   80.000000  ...  100.0  100.0  100.0   \nLIVT        100.000000  100.000000  100.000000  ...    0.0    0.0    0.0   \n...                ...         ...         ...  ...    ...    ...    ...   \nYAEER        20.000000   20.000000   40.000000  ...   60.0   60.0   60.0   \nYPF          33.333333   33.333333   66.666667  ...    0.0    0.0    0.0   \nYPGIA        40.000000   60.000000  100.000000  ...    0.0    0.0    0.0   \nYPIL         25.000000   25.000000   50.000000  ...    0.0    0.0    0.0   \nYRGGLEPINF   30.000000   40.000000   70.000000  ...   20.0   20.0   20.0   \n\n              189    190         191         192         193         194  \\\n0                                                                          \nMDFLI        40.0   40.0   20.000000   20.000000   20.000000   20.000000   \nMFDL         75.0   75.0   25.000000   25.000000   25.000000   25.000000   \nMDLA         50.0   50.0   25.000000   25.000000   25.000000   25.000000   \nLIVTQ       100.0  100.0   80.000000   80.000000   80.000000   80.000000   \nLIVT          0.0    0.0  100.000000  100.000000  100.000000  100.000000   \n...           ...    ...         ...         ...         ...         ...   \nYAEER        80.0  100.0   20.000000   20.000000   20.000000   20.000000   \nYPF           0.0    0.0   33.333333   33.333333   33.333333   33.333333   \nYPGIA         0.0    0.0   20.000000   20.000000   20.000000   20.000000   \nYPIL          0.0    0.0   25.000000   25.000000   25.000000   25.000000   \nYRGGLEPINF   60.0   90.0   10.000000   10.000000   10.000000   10.000000   \n\n                   195  \n0                       \nMDFLI        20.000000  \nMFDL         25.000000  \nMDLA         25.000000  \nLIVTQ        80.000000  \nLIVT        100.000000  \n...                ...  \nYAEER        20.000000  \nYPF          66.666667  \nYPGIA        40.000000  \nYPIL         50.000000  \nYRGGLEPINF   70.000000  \n\n[1020 rows x 195 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>...</th>\n      <th>186</th>\n      <th>187</th>\n      <th>188</th>\n      <th>189</th>\n      <th>190</th>\n      <th>191</th>\n      <th>192</th>\n      <th>193</th>\n      <th>194</th>\n      <th>195</th>\n    </tr>\n    <tr>\n      <th>0</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>MDFLI</th>\n      <td>40.0</td>\n      <td>40.0</td>\n      <td>40.0</td>\n      <td>40.0</td>\n      <td>40.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>40.0</td>\n      <td>40.0</td>\n      <td>40.0</td>\n      <td>40.0</td>\n      <td>40.0</td>\n      <td>20.000000</td>\n      <td>20.000000</td>\n      <td>20.000000</td>\n      <td>20.000000</td>\n      <td>20.000000</td>\n    </tr>\n    <tr>\n      <th>MFDL</th>\n      <td>75.0</td>\n      <td>75.0</td>\n      <td>75.0</td>\n      <td>75.0</td>\n      <td>75.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>75.0</td>\n      <td>75.0</td>\n      <td>75.0</td>\n      <td>75.0</td>\n      <td>75.0</td>\n      <td>25.000000</td>\n      <td>25.000000</td>\n      <td>25.000000</td>\n      <td>25.000000</td>\n      <td>25.000000</td>\n    </tr>\n    <tr>\n      <th>MDLA</th>\n      <td>50.0</td>\n      <td>50.0</td>\n      <td>50.0</td>\n      <td>50.0</td>\n      <td>50.0</td>\n      <td>100.000000</td>\n      <td>100.000000</td>\n      <td>100.000000</td>\n      <td>100.000000</td>\n      <td>100.000000</td>\n      <td>...</td>\n      <td>50.0</td>\n      <td>50.0</td>\n      <td>50.0</td>\n      <td>50.0</td>\n      <td>50.0</td>\n      <td>25.000000</td>\n      <td>25.000000</td>\n      <td>25.000000</td>\n      <td>25.000000</td>\n      <td>25.000000</td>\n    </tr>\n    <tr>\n      <th>LIVTQ</th>\n      <td>100.0</td>\n      <td>100.0</td>\n      <td>100.0</td>\n      <td>100.0</td>\n      <td>100.0</td>\n      <td>80.000000</td>\n      <td>80.000000</td>\n      <td>80.000000</td>\n      <td>80.000000</td>\n      <td>80.000000</td>\n      <td>...</td>\n      <td>100.0</td>\n      <td>100.0</td>\n      <td>100.0</td>\n      <td>100.0</td>\n      <td>100.0</td>\n      <td>80.000000</td>\n      <td>80.000000</td>\n      <td>80.000000</td>\n      <td>80.000000</td>\n      <td>80.000000</td>\n    </tr>\n    <tr>\n      <th>LIVT</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>100.000000</td>\n      <td>100.000000</td>\n      <td>100.000000</td>\n      <td>100.000000</td>\n      <td>100.000000</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>100.000000</td>\n      <td>100.000000</td>\n      <td>100.000000</td>\n      <td>100.000000</td>\n      <td>100.000000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>YAEER</th>\n      <td>60.0</td>\n      <td>60.0</td>\n      <td>60.0</td>\n      <td>80.0</td>\n      <td>100.0</td>\n      <td>20.000000</td>\n      <td>20.000000</td>\n      <td>20.000000</td>\n      <td>20.000000</td>\n      <td>40.000000</td>\n      <td>...</td>\n      <td>60.0</td>\n      <td>60.0</td>\n      <td>60.0</td>\n      <td>80.0</td>\n      <td>100.0</td>\n      <td>20.000000</td>\n      <td>20.000000</td>\n      <td>20.000000</td>\n      <td>20.000000</td>\n      <td>20.000000</td>\n    </tr>\n    <tr>\n      <th>YPF</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>33.333333</td>\n      <td>33.333333</td>\n      <td>33.333333</td>\n      <td>33.333333</td>\n      <td>66.666667</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>33.333333</td>\n      <td>33.333333</td>\n      <td>33.333333</td>\n      <td>33.333333</td>\n      <td>66.666667</td>\n    </tr>\n    <tr>\n      <th>YPGIA</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>20.000000</td>\n      <td>20.000000</td>\n      <td>40.000000</td>\n      <td>60.000000</td>\n      <td>100.000000</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>20.000000</td>\n      <td>20.000000</td>\n      <td>20.000000</td>\n      <td>20.000000</td>\n      <td>40.000000</td>\n    </tr>\n    <tr>\n      <th>YPIL</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>25.000000</td>\n      <td>25.000000</td>\n      <td>25.000000</td>\n      <td>25.000000</td>\n      <td>50.000000</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>25.000000</td>\n      <td>25.000000</td>\n      <td>25.000000</td>\n      <td>25.000000</td>\n      <td>50.000000</td>\n    </tr>\n    <tr>\n      <th>YRGGLEPINF</th>\n      <td>20.0</td>\n      <td>20.0</td>\n      <td>20.0</td>\n      <td>60.0</td>\n      <td>90.0</td>\n      <td>10.000000</td>\n      <td>10.000000</td>\n      <td>30.000000</td>\n      <td>40.000000</td>\n      <td>70.000000</td>\n      <td>...</td>\n      <td>20.0</td>\n      <td>20.0</td>\n      <td>20.0</td>\n      <td>60.0</td>\n      <td>90.0</td>\n      <td>10.000000</td>\n      <td>10.000000</td>\n      <td>10.000000</td>\n      <td>10.000000</td>\n      <td>70.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>1020 rows × 195 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5vnRH5gaJCHF",
    "outputId": "29337cfa-86f0-48bd-8fa5-166b0e8b6c91",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1020, 195)\n",
      "(1020,)\n",
      "394\n",
      "626\n"
     ]
    }
   ],
   "source": [
    "print(X_new.shape)\n",
    "print(y_new.shape)\n",
    "print(np.count_nonzero(y_new==0))\n",
    "print(np.count_nonzero(y_new==1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lDxnvWKb1rTP",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Cross-validation for hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "7ljJnDTp4Pd6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import statistics\n",
    "from sklearn.metrics import balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "RZWpqaGg1yoU",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# dataset splitting \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_whole, X_ind_test, y_train_whole, y_ind_test =  train_test_split( X_new, y_new, test_size=0.2, random_state=1111)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5P1fK2FJApwf",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SZl8OlLhSdl-",
    "outputId": "aa4c5d40-54f5-42d8-d9e4-5d3a1dafbbef",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(max_iter=2000, penalty='none') 0.763 0.046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# logistic regresion non penality\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "acc_cv_mean_collection=[]\n",
    "C_para = [0.5]\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "for i in C_para:\n",
    "    acc_cv_collection = []\n",
    "    clf = LogisticRegression(penalty= 'none', max_iter = 2000)  # need to tune the hyperparameters\n",
    "    skf = StratifiedKFold(n_splits=10)\n",
    "    for train, test in skf.split(X_train_whole, y_train_whole):\n",
    "        X_train, X_valid, y_train, y_valid = np.take(X_train_whole, train.tolist(), axis=0), np.take(X_train_whole,\n",
    "                                                                                                     test.tolist(),\n",
    "                                                                                                     axis=0), np.take(\n",
    "            y_train_whole, train.tolist(), axis=0), np.take(y_train_whole, test.tolist(), axis=0)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_valid_pred = clf.predict(X_valid)\n",
    "        acc_cv = balanced_accuracy_score(y_valid, y_valid_pred)\n",
    "        acc_cv_collection.append(acc_cv)\n",
    "    acc_cv_mean_collection.append(round(statistics.mean(acc_cv_collection),3))\n",
    "    print(clf,round(statistics.mean(acc_cv_collection),3), round(statistics.stdev(acc_cv_collection),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w3zkmofkS7Wi",
    "outputId": "db88c72c-e152-4ae9-94b5-5707447c6816",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.5, max_iter=5000, penalty='l1', solver='saga') 0.746 0.041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1, max_iter=5000, penalty='l1', solver='saga') 0.743 0.034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.5, max_iter=5000, penalty='l1', solver='saga') 0.744 0.034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=2, max_iter=5000, penalty='l1', solver='saga') 0.744 0.034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=2.5, max_iter=5000, penalty='l1', solver='saga') 0.743 0.034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=4, max_iter=5000, penalty='l1', solver='saga') 0.743 0.034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=6, max_iter=5000, penalty='l1', solver='saga') 0.743 0.034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=8, max_iter=5000, penalty='l1', solver='saga') 0.743 0.034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=13, max_iter=5000, penalty='l1', solver='saga') 0.743 0.034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=14, max_iter=5000, penalty='l1', solver='saga') 0.743 0.034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=15, max_iter=5000, penalty='l1', solver='saga') 0.743 0.034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=16, max_iter=5000, penalty='l1', solver='saga') 0.743 0.034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=20, max_iter=5000, penalty='l1', solver='saga') 0.743 0.034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=30, max_iter=5000, penalty='l1', solver='saga') 0.742 0.036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=40, max_iter=5000, penalty='l1', solver='saga') 0.742 0.036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=50, max_iter=5000, penalty='l1', solver='saga') 0.742 0.036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=60, max_iter=5000, penalty='l1', solver='saga') 0.742 0.036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=70, max_iter=5000, penalty='l1', solver='saga') 0.742 0.036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=80, max_iter=5000, penalty='l1', solver='saga') 0.742 0.036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=90, max_iter=5000, penalty='l1', solver='saga') 0.742 0.036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=100, max_iter=5000, penalty='l1', solver='saga') 0.742 0.036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=125, max_iter=5000, penalty='l1', solver='saga') 0.742 0.036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# logistic regresion l1 penality\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "acc_cv_mean_collection=[]\n",
    "C_para = [0.5,1,1.5,2,2.5,4,6,8,13,14,15,16,20,30,40, 50,60,70, 80, 90 ,100,125]\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "for i in C_para:\n",
    "    acc_cv_collection = []\n",
    "    clf = LogisticRegression(penalty= 'l1', solver= 'saga', C=i, max_iter = 5000)  # need to tune the hyperparameters\n",
    "    skf = StratifiedKFold(n_splits=10)\n",
    "    for train, test in skf.split(X_train_whole, y_train_whole):\n",
    "        X_train, X_valid, y_train, y_valid = np.take(X_train_whole, train.tolist(), axis=0), np.take(X_train_whole,\n",
    "                                                                                                     test.tolist(),\n",
    "                                                                                                     axis=0), np.take(\n",
    "            y_train_whole, train.tolist(), axis=0), np.take(y_train_whole, test.tolist(), axis=0)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_valid_pred = clf.predict(X_valid)\n",
    "        acc_cv = balanced_accuracy_score(y_valid, y_valid_pred)\n",
    "        acc_cv_collection.append(acc_cv)\n",
    "    acc_cv_mean_collection.append(round(statistics.mean(acc_cv_collection),3))\n",
    "    print(clf,round(statistics.mean(acc_cv_collection),3), round(statistics.stdev(acc_cv_collection),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GtfLMPXiSVdm",
    "outputId": "a7d31ab0-e7b8-468d-a3f7-ea19b6d65295",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.5, max_iter=5000) 0.758 0.045\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 15\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m train, test \u001B[38;5;129;01min\u001B[39;00m skf\u001B[38;5;241m.\u001B[39msplit(X_train_whole, y_train_whole):\n\u001B[1;32m     11\u001B[0m     X_train, X_valid, y_train, y_valid \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mtake(X_train_whole, train\u001B[38;5;241m.\u001B[39mtolist(), axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m), np\u001B[38;5;241m.\u001B[39mtake(X_train_whole,\n\u001B[1;32m     12\u001B[0m                                                                                                  test\u001B[38;5;241m.\u001B[39mtolist(),\n\u001B[1;32m     13\u001B[0m                                                                                                  axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m), np\u001B[38;5;241m.\u001B[39mtake(\n\u001B[1;32m     14\u001B[0m         y_train_whole, train\u001B[38;5;241m.\u001B[39mtolist(), axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m), np\u001B[38;5;241m.\u001B[39mtake(y_train_whole, test\u001B[38;5;241m.\u001B[39mtolist(), axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m---> 15\u001B[0m     \u001B[43mclf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     16\u001B[0m     y_valid_pred \u001B[38;5;241m=\u001B[39m clf\u001B[38;5;241m.\u001B[39mpredict(X_valid)\n\u001B[1;32m     17\u001B[0m     acc_cv \u001B[38;5;241m=\u001B[39m balanced_accuracy_score(y_valid, y_valid_pred)\n",
      "File \u001B[0;32m~/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:1291\u001B[0m, in \u001B[0;36mLogisticRegression.fit\u001B[0;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[1;32m   1288\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1289\u001B[0m     n_threads \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m-> 1291\u001B[0m fold_coefs_ \u001B[38;5;241m=\u001B[39m \u001B[43mParallel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprefer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprefer\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1292\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpath_func\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1293\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1294\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1295\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpos_class\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclass_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1296\u001B[0m \u001B[43m        \u001B[49m\u001B[43mCs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mC_\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1297\u001B[0m \u001B[43m        \u001B[49m\u001B[43ml1_ratio\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43ml1_ratio\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1298\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfit_intercept\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_intercept\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1299\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtol\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtol\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1300\u001B[0m \u001B[43m        \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1301\u001B[0m \u001B[43m        \u001B[49m\u001B[43msolver\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msolver\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1302\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmulti_class\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmulti_class\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1303\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_iter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_iter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1304\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclass_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclass_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1305\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcheck_input\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   1306\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrandom_state\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1307\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcoef\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwarm_start_coef_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1308\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpenalty\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpenalty\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1309\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_squared_sum\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_squared_sum\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1310\u001B[0m \u001B[43m        \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1311\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_threads\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_threads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1312\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1313\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mclass_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwarm_start_coef_\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mzip\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mclasses_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwarm_start_coef\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1314\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1316\u001B[0m fold_coefs_, _, n_iter_ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mfold_coefs_)\n\u001B[1;32m   1317\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_iter_ \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(n_iter_, dtype\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mint32)[:, \u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[0;32m~/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/utils/parallel.py:63\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m     58\u001B[0m config \u001B[38;5;241m=\u001B[39m get_config()\n\u001B[1;32m     59\u001B[0m iterable_with_config \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m     60\u001B[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[1;32m     61\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[1;32m     62\u001B[0m )\n\u001B[0;32m---> 63\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterable_with_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/joblib/parallel.py:1085\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1076\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1077\u001B[0m     \u001B[38;5;66;03m# Only set self._iterating to True if at least a batch\u001B[39;00m\n\u001B[1;32m   1078\u001B[0m     \u001B[38;5;66;03m# was dispatched. In particular this covers the edge\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1082\u001B[0m     \u001B[38;5;66;03m# was very quick and its callback already dispatched all the\u001B[39;00m\n\u001B[1;32m   1083\u001B[0m     \u001B[38;5;66;03m# remaining jobs.\u001B[39;00m\n\u001B[1;32m   1084\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m-> 1085\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdispatch_one_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m   1086\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_original_iterator \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1088\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdispatch_one_batch(iterator):\n",
      "File \u001B[0;32m~/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/joblib/parallel.py:901\u001B[0m, in \u001B[0;36mParallel.dispatch_one_batch\u001B[0;34m(self, iterator)\u001B[0m\n\u001B[1;32m    899\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m    900\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 901\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dispatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtasks\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    902\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/joblib/parallel.py:819\u001B[0m, in \u001B[0;36mParallel._dispatch\u001B[0;34m(self, batch)\u001B[0m\n\u001B[1;32m    817\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[1;32m    818\u001B[0m     job_idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs)\n\u001B[0;32m--> 819\u001B[0m     job \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_backend\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_async\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    820\u001B[0m     \u001B[38;5;66;03m# A job can complete so quickly than its callback is\u001B[39;00m\n\u001B[1;32m    821\u001B[0m     \u001B[38;5;66;03m# called before we get here, causing self._jobs to\u001B[39;00m\n\u001B[1;32m    822\u001B[0m     \u001B[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001B[39;00m\n\u001B[1;32m    823\u001B[0m     \u001B[38;5;66;03m# used (rather than .append) in the following line\u001B[39;00m\n\u001B[1;32m    824\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs\u001B[38;5;241m.\u001B[39minsert(job_idx, job)\n",
      "File \u001B[0;32m~/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/joblib/_parallel_backends.py:208\u001B[0m, in \u001B[0;36mSequentialBackend.apply_async\u001B[0;34m(self, func, callback)\u001B[0m\n\u001B[1;32m    206\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply_async\u001B[39m(\u001B[38;5;28mself\u001B[39m, func, callback\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    207\u001B[0m     \u001B[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001B[39;00m\n\u001B[0;32m--> 208\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mImmediateResult\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    209\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m callback:\n\u001B[1;32m    210\u001B[0m         callback(result)\n",
      "File \u001B[0;32m~/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/joblib/_parallel_backends.py:597\u001B[0m, in \u001B[0;36mImmediateResult.__init__\u001B[0;34m(self, batch)\u001B[0m\n\u001B[1;32m    594\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, batch):\n\u001B[1;32m    595\u001B[0m     \u001B[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001B[39;00m\n\u001B[1;32m    596\u001B[0m     \u001B[38;5;66;03m# arguments in memory\u001B[39;00m\n\u001B[0;32m--> 597\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresults \u001B[38;5;241m=\u001B[39m \u001B[43mbatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/joblib/parallel.py:288\u001B[0m, in \u001B[0;36mBatchedCalls.__call__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    284\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    285\u001B[0m     \u001B[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001B[39;00m\n\u001B[1;32m    286\u001B[0m     \u001B[38;5;66;03m# change the default number of processes to -1\u001B[39;00m\n\u001B[1;32m    287\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m parallel_backend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_jobs):\n\u001B[0;32m--> 288\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    289\u001B[0m                 \u001B[38;5;28;01mfor\u001B[39;00m func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems]\n",
      "File \u001B[0;32m~/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/joblib/parallel.py:288\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    284\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    285\u001B[0m     \u001B[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001B[39;00m\n\u001B[1;32m    286\u001B[0m     \u001B[38;5;66;03m# change the default number of processes to -1\u001B[39;00m\n\u001B[1;32m    287\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m parallel_backend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_jobs):\n\u001B[0;32m--> 288\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    289\u001B[0m                 \u001B[38;5;28;01mfor\u001B[39;00m func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems]\n",
      "File \u001B[0;32m~/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/utils/parallel.py:123\u001B[0m, in \u001B[0;36m_FuncWrapper.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    121\u001B[0m     config \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m    122\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mconfig):\n\u001B[0;32m--> 123\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:450\u001B[0m, in \u001B[0;36m_logistic_regression_path\u001B[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001B[0m\n\u001B[1;32m    446\u001B[0m l2_reg_strength \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1.0\u001B[39m \u001B[38;5;241m/\u001B[39m C\n\u001B[1;32m    447\u001B[0m iprint \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m50\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m100\u001B[39m, \u001B[38;5;241m101\u001B[39m][\n\u001B[1;32m    448\u001B[0m     np\u001B[38;5;241m.\u001B[39msearchsorted(np\u001B[38;5;241m.\u001B[39marray([\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m3\u001B[39m]), verbose)\n\u001B[1;32m    449\u001B[0m ]\n\u001B[0;32m--> 450\u001B[0m opt_res \u001B[38;5;241m=\u001B[39m \u001B[43moptimize\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mminimize\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    451\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    452\u001B[0m \u001B[43m    \u001B[49m\u001B[43mw0\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    453\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mL-BFGS-B\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    454\u001B[0m \u001B[43m    \u001B[49m\u001B[43mjac\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    455\u001B[0m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43ml2_reg_strength\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_threads\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    456\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43miprint\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43miprint\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mgtol\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtol\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmaxiter\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_iter\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    457\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    458\u001B[0m n_iter_i \u001B[38;5;241m=\u001B[39m _check_optimize_result(\n\u001B[1;32m    459\u001B[0m     solver,\n\u001B[1;32m    460\u001B[0m     opt_res,\n\u001B[1;32m    461\u001B[0m     max_iter,\n\u001B[1;32m    462\u001B[0m     extra_warning_msg\u001B[38;5;241m=\u001B[39m_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n\u001B[1;32m    463\u001B[0m )\n\u001B[1;32m    464\u001B[0m w0, loss \u001B[38;5;241m=\u001B[39m opt_res\u001B[38;5;241m.\u001B[39mx, opt_res\u001B[38;5;241m.\u001B[39mfun\n",
      "File \u001B[0;32m~/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/scipy/optimize/_minimize.py:696\u001B[0m, in \u001B[0;36mminimize\u001B[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001B[0m\n\u001B[1;32m    693\u001B[0m     res \u001B[38;5;241m=\u001B[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001B[1;32m    694\u001B[0m                              \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions)\n\u001B[1;32m    695\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m meth \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124ml-bfgs-b\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m--> 696\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43m_minimize_lbfgsb\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfun\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx0\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mjac\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbounds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    697\u001B[0m \u001B[43m                           \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallback\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    698\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m meth \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtnc\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m    699\u001B[0m     res \u001B[38;5;241m=\u001B[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001B[38;5;241m=\u001B[39mcallback,\n\u001B[1;32m    700\u001B[0m                         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moptions)\n",
      "File \u001B[0;32m~/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/scipy/optimize/_lbfgsb_py.py:359\u001B[0m, in \u001B[0;36m_minimize_lbfgsb\u001B[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001B[0m\n\u001B[1;32m    353\u001B[0m task_str \u001B[38;5;241m=\u001B[39m task\u001B[38;5;241m.\u001B[39mtobytes()\n\u001B[1;32m    354\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m task_str\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFG\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[1;32m    355\u001B[0m     \u001B[38;5;66;03m# The minimization routine wants f and g at the current x.\u001B[39;00m\n\u001B[1;32m    356\u001B[0m     \u001B[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001B[39;00m\n\u001B[1;32m    357\u001B[0m     \u001B[38;5;66;03m# until the completion of the current minimization iteration.\u001B[39;00m\n\u001B[1;32m    358\u001B[0m     \u001B[38;5;66;03m# Overwrite f and g:\u001B[39;00m\n\u001B[0;32m--> 359\u001B[0m     f, g \u001B[38;5;241m=\u001B[39m \u001B[43mfunc_and_grad\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    360\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m task_str\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNEW_X\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[1;32m    361\u001B[0m     \u001B[38;5;66;03m# new iteration\u001B[39;00m\n\u001B[1;32m    362\u001B[0m     n_iterations \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[0;32m~/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py:285\u001B[0m, in \u001B[0;36mScalarFunction.fun_and_grad\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    283\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m np\u001B[38;5;241m.\u001B[39marray_equal(x, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mx):\n\u001B[1;32m    284\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_x_impl(x)\n\u001B[0;32m--> 285\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_update_fun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    286\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_grad()\n\u001B[1;32m    287\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mg\n",
      "File \u001B[0;32m~/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py:251\u001B[0m, in \u001B[0;36mScalarFunction._update_fun\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    249\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_update_fun\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    250\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf_updated:\n\u001B[0;32m--> 251\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_update_fun_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    252\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf_updated \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py:155\u001B[0m, in \u001B[0;36mScalarFunction.__init__.<locals>.update_fun\u001B[0;34m()\u001B[0m\n\u001B[1;32m    154\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mupdate_fun\u001B[39m():\n\u001B[0;32m--> 155\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf \u001B[38;5;241m=\u001B[39m \u001B[43mfun_wrapped\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py:137\u001B[0m, in \u001B[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001B[0;34m(x)\u001B[0m\n\u001B[1;32m    133\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnfev \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    134\u001B[0m \u001B[38;5;66;03m# Send a copy because the user may overwrite it.\u001B[39;00m\n\u001B[1;32m    135\u001B[0m \u001B[38;5;66;03m# Overwriting results in undefined behaviour because\u001B[39;00m\n\u001B[1;32m    136\u001B[0m \u001B[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001B[39;00m\n\u001B[0;32m--> 137\u001B[0m fx \u001B[38;5;241m=\u001B[39m \u001B[43mfun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    138\u001B[0m \u001B[38;5;66;03m# Make sure the function returns a true scalar\u001B[39;00m\n\u001B[1;32m    139\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m np\u001B[38;5;241m.\u001B[39misscalar(fx):\n",
      "File \u001B[0;32m~/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/scipy/optimize/_optimize.py:76\u001B[0m, in \u001B[0;36mMemoizeJac.__call__\u001B[0;34m(self, x, *args)\u001B[0m\n\u001B[1;32m     74\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, x, \u001B[38;5;241m*\u001B[39margs):\n\u001B[1;32m     75\u001B[0m     \u001B[38;5;124;03m\"\"\" returns the function value \"\"\"\u001B[39;00m\n\u001B[0;32m---> 76\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_compute_if_needed\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     77\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_value\n",
      "File \u001B[0;32m~/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/scipy/optimize/_optimize.py:70\u001B[0m, in \u001B[0;36mMemoizeJac._compute_if_needed\u001B[0;34m(self, x, *args)\u001B[0m\n\u001B[1;32m     68\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m np\u001B[38;5;241m.\u001B[39mall(x \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mx) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_value \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mjac \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mx \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(x)\u001B[38;5;241m.\u001B[39mcopy()\n\u001B[0;32m---> 70\u001B[0m     fg \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     71\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mjac \u001B[38;5;241m=\u001B[39m fg[\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_value \u001B[38;5;241m=\u001B[39m fg[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[0;32m~/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_linear_loss.py:289\u001B[0m, in \u001B[0;36mLinearModelLoss.loss_gradient\u001B[0;34m(self, coef, X, y, sample_weight, l2_reg_strength, n_threads, raw_prediction)\u001B[0m\n\u001B[1;32m    287\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbase_loss\u001B[38;5;241m.\u001B[39mis_multiclass:\n\u001B[1;32m    288\u001B[0m     grad \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mempty_like(coef, dtype\u001B[38;5;241m=\u001B[39mweights\u001B[38;5;241m.\u001B[39mdtype)\n\u001B[0;32m--> 289\u001B[0m     grad[:n_features] \u001B[38;5;241m=\u001B[39m \u001B[43mX\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mT\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m@\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mgrad_pointwise\u001B[49m \u001B[38;5;241m+\u001B[39m l2_reg_strength \u001B[38;5;241m*\u001B[39m weights\n\u001B[1;32m    290\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfit_intercept:\n\u001B[1;32m    291\u001B[0m         grad[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m=\u001B[39m grad_pointwise\u001B[38;5;241m.\u001B[39msum()\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# logistic regresion\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "acc_cv_mean_collection=[]\n",
    "C_para = [0.5,1,1.5,2,2.5,4,6,8,13,14,15,16,20,30,40, 50,60,70, 80, 90 ,100,125, 500, 1000,2000,4000,10000]\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "for i in C_para:\n",
    "    acc_cv_collection = []\n",
    "    clf = LogisticRegression(C=i, max_iter = 5000)  # need to tune the hyperparameters\n",
    "    skf = StratifiedKFold(n_splits=10)\n",
    "    for train, test in skf.split(X_train_whole, y_train_whole):\n",
    "        X_train, X_valid, y_train, y_valid = np.take(X_train_whole, train.tolist(), axis=0), np.take(X_train_whole,\n",
    "                                                                                                     test.tolist(),\n",
    "                                                                                                     axis=0), np.take(\n",
    "            y_train_whole, train.tolist(), axis=0), np.take(y_train_whole, test.tolist(), axis=0)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_valid_pred = clf.predict(X_valid)\n",
    "        acc_cv = balanced_accuracy_score(y_valid, y_valid_pred)\n",
    "        acc_cv_collection.append(acc_cv)\n",
    "    acc_cv_mean_collection.append(round(statistics.mean(acc_cv_collection),3))\n",
    "    print(clf,round(statistics.mean(acc_cv_collection),3), round(statistics.stdev(acc_cv_collection),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YjMK3qEHAvLV",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fsAq7RSnGugd",
    "outputId": "ffe95c84-3b33-4dbb-b54b-cbc67b463af4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(max_depth=1, max_features='log2', n_estimators=80) 0.5 0.0\n",
      "RandomForestClassifier(max_depth=1, n_estimators=80) 0.5 0.0\n",
      "RandomForestClassifier(max_depth=2, max_features='log2', n_estimators=80) 0.606 0.032\n",
      "RandomForestClassifier(max_depth=2, n_estimators=80) 0.642 0.044\n",
      "RandomForestClassifier(max_depth=3, max_features='log2', n_estimators=80) 0.666 0.046\n",
      "RandomForestClassifier(max_depth=3, n_estimators=80) 0.713 0.064\n",
      "RandomForestClassifier(max_depth=4, max_features='log2', n_estimators=80) 0.708 0.07\n",
      "RandomForestClassifier(max_depth=4, n_estimators=80) 0.732 0.057\n",
      "RandomForestClassifier(max_depth=1, max_features='log2', n_estimators=160) 0.5 0.0\n",
      "RandomForestClassifier(max_depth=1, n_estimators=160) 0.502 0.005\n",
      "RandomForestClassifier(max_depth=2, max_features='log2', n_estimators=160) 0.617 0.032\n",
      "RandomForestClassifier(max_depth=2, n_estimators=160) 0.63 0.038\n",
      "RandomForestClassifier(max_depth=3, max_features='log2', n_estimators=160) 0.677 0.045\n",
      "RandomForestClassifier(max_depth=3, n_estimators=160) 0.696 0.063\n",
      "RandomForestClassifier(max_depth=4, max_features='log2', n_estimators=160) 0.714 0.054\n",
      "RandomForestClassifier(max_depth=4, n_estimators=160) 0.732 0.06\n",
      "RandomForestClassifier(max_depth=1, max_features='log2', n_estimators=320) 0.5 0.0\n",
      "RandomForestClassifier(max_depth=1, n_estimators=320) 0.5 0.0\n",
      "RandomForestClassifier(max_depth=2, max_features='log2', n_estimators=320) 0.616 0.035\n",
      "RandomForestClassifier(max_depth=2, n_estimators=320) 0.643 0.046\n",
      "RandomForestClassifier(max_depth=3, max_features='log2', n_estimators=320) 0.684 0.062\n",
      "RandomForestClassifier(max_depth=3, n_estimators=320) 0.698 0.06\n",
      "RandomForestClassifier(max_depth=4, max_features='log2', n_estimators=320) 0.723 0.048\n",
      "RandomForestClassifier(max_depth=4, n_estimators=320) 0.729 0.059\n",
      "RandomForestClassifier(max_depth=1, max_features='log2', n_estimators=480) 0.5 0.0\n",
      "RandomForestClassifier(max_depth=1, n_estimators=480) 0.5 0.0\n",
      "RandomForestClassifier(max_depth=2, max_features='log2', n_estimators=480) 0.607 0.03\n",
      "RandomForestClassifier(max_depth=2, n_estimators=480) 0.637 0.037\n",
      "RandomForestClassifier(max_depth=3, max_features='log2', n_estimators=480) 0.676 0.06\n",
      "RandomForestClassifier(max_depth=3, n_estimators=480) 0.712 0.059\n",
      "RandomForestClassifier(max_depth=4, max_features='log2', n_estimators=480) 0.726 0.052\n",
      "RandomForestClassifier(max_depth=4, n_estimators=480) 0.735 0.049\n",
      "RandomForestClassifier(max_depth=1, max_features='log2', n_estimators=640) 0.5 0.0\n",
      "RandomForestClassifier(max_depth=1, n_estimators=640) 0.5 0.0\n",
      "RandomForestClassifier(max_depth=2, max_features='log2', n_estimators=640) 0.612 0.032\n",
      "RandomForestClassifier(max_depth=2, n_estimators=640) 0.64 0.042\n",
      "RandomForestClassifier(max_depth=3, max_features='log2', n_estimators=640) 0.684 0.056\n",
      "RandomForestClassifier(max_depth=3, n_estimators=640) 0.7 0.063\n",
      "RandomForestClassifier(max_depth=4, max_features='log2', n_estimators=640) 0.724 0.059\n",
      "RandomForestClassifier(max_depth=4, n_estimators=640) 0.733 0.051\n",
      "RandomForestClassifier(max_depth=1, max_features='log2', n_estimators=1280) 0.5 0.0\n",
      "RandomForestClassifier(max_depth=1, n_estimators=1280) 0.5 0.0\n",
      "RandomForestClassifier(max_depth=2, max_features='log2', n_estimators=1280) 0.614 0.034\n",
      "RandomForestClassifier(max_depth=2, n_estimators=1280) 0.64 0.042\n",
      "RandomForestClassifier(max_depth=3, max_features='log2', n_estimators=1280) 0.681 0.056\n",
      "RandomForestClassifier(max_depth=3, n_estimators=1280) 0.711 0.061\n",
      "RandomForestClassifier(max_depth=4, max_features='log2', n_estimators=1280) 0.723 0.052\n",
      "RandomForestClassifier(max_depth=4, n_estimators=1280) 0.726 0.056\n"
     ]
    }
   ],
   "source": [
    "# random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "\n",
    "acc_cv_mean_collection = []\n",
    "n_estimatorsint = [80, 160, 320, 480, 640, 1280]\n",
    "max_depthint = [1, 2, 3, 4]\n",
    "max_features = ['log2', 'sqrt']\n",
    "\n",
    "for i in n_estimatorsint:\n",
    "    for j in max_depthint:\n",
    "        for p in max_features:\n",
    "            acc_cv_collection = []\n",
    "            clf = RandomForestClassifier(n_estimators=i, max_depth=j, max_features=p)\n",
    "            from sklearn.model_selection import cross_val_score, KFold, StratifiedKFold\n",
    "            skf = StratifiedKFold(n_splits=10)\n",
    "            for train, test in skf.split(X_train_whole, y_train_whole):\n",
    "                X_train, X_valid, y_train, y_valid = np.take(X_train_whole, train.tolist(), axis=0), np.take(X_train_whole,\n",
    "                                                                                                                test.tolist(),\n",
    "                                                                                                                axis=0), np.take(\n",
    "                    y_train_whole, train.tolist(), axis=0), np.take(y_train_whole, test.tolist(), axis=0)\n",
    "                clf.fit(X_train, y_train)\n",
    "                y_valid_pred = clf.predict(X_valid)\n",
    "                acc_cv = balanced_accuracy_score(y_valid, y_valid_pred)\n",
    "                acc_cv_collection.append(acc_cv)\n",
    "            acc_cv_mean_collection.append(round(statistics.mean(acc_cv_collection),3))\n",
    "            print(clf,round(statistics.mean(acc_cv_collection),3), round(statistics.stdev(acc_cv_collection),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cp1Han6zB1vU",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tG3BrQXo44in",
    "outputId": "fc0ee4cb-0e90-479f-c3ff-22141e876015",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(leaf_size=10, n_neighbors=2) 0.707 0.035\n",
      "KNeighborsClassifier(leaf_size=20, n_neighbors=2) 0.707 0.035\n",
      "KNeighborsClassifier(n_neighbors=2) 0.707 0.035\n",
      "KNeighborsClassifier(leaf_size=40, n_neighbors=2) 0.707 0.035\n",
      "KNeighborsClassifier(leaf_size=50, n_neighbors=2) 0.707 0.035\n",
      "KNeighborsClassifier(leaf_size=60, n_neighbors=2) 0.707 0.035\n",
      "KNeighborsClassifier(leaf_size=70, n_neighbors=2) 0.707 0.035\n",
      "KNeighborsClassifier(leaf_size=80, n_neighbors=2) 0.707 0.035\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=10, n_neighbors=2) 0.705 0.034\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=20, n_neighbors=2) 0.705 0.034\n",
      "KNeighborsClassifier(algorithm='ball_tree', n_neighbors=2) 0.705 0.034\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=40, n_neighbors=2) 0.705 0.034\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=50, n_neighbors=2) 0.705 0.034\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=60, n_neighbors=2) 0.705 0.034\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=70, n_neighbors=2) 0.705 0.034\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=80, n_neighbors=2) 0.705 0.034\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=10, n_neighbors=2) 0.705 0.034\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=20, n_neighbors=2) 0.705 0.034\n",
      "KNeighborsClassifier(algorithm='kd_tree', n_neighbors=2) 0.705 0.034\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=40, n_neighbors=2) 0.705 0.034\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=50, n_neighbors=2) 0.705 0.034\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=60, n_neighbors=2) 0.705 0.034\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=70, n_neighbors=2) 0.705 0.034\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=80, n_neighbors=2) 0.705 0.034\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=10, n_neighbors=2) 0.707 0.035\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=20, n_neighbors=2) 0.707 0.035\n",
      "KNeighborsClassifier(algorithm='brute', n_neighbors=2) 0.707 0.035\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=40, n_neighbors=2) 0.707 0.035\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=50, n_neighbors=2) 0.707 0.035\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=60, n_neighbors=2) 0.707 0.035\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=70, n_neighbors=2) 0.707 0.035\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=80, n_neighbors=2) 0.707 0.035\n",
      "KNeighborsClassifier(leaf_size=10, n_neighbors=2, weights='distance') 0.717 0.053\n",
      "KNeighborsClassifier(leaf_size=20, n_neighbors=2, weights='distance') 0.717 0.053\n",
      "KNeighborsClassifier(n_neighbors=2, weights='distance') 0.717 0.053\n",
      "KNeighborsClassifier(leaf_size=40, n_neighbors=2, weights='distance') 0.717 0.053\n",
      "KNeighborsClassifier(leaf_size=50, n_neighbors=2, weights='distance') 0.717 0.053\n",
      "KNeighborsClassifier(leaf_size=60, n_neighbors=2, weights='distance') 0.717 0.053\n",
      "KNeighborsClassifier(leaf_size=70, n_neighbors=2, weights='distance') 0.717 0.053\n",
      "KNeighborsClassifier(leaf_size=80, n_neighbors=2, weights='distance') 0.717 0.053\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=10, n_neighbors=2,\n",
      "                     weights='distance') 0.717 0.053\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=20, n_neighbors=2,\n",
      "                     weights='distance') 0.717 0.053\n",
      "KNeighborsClassifier(algorithm='ball_tree', n_neighbors=2, weights='distance') 0.717 0.053\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=40, n_neighbors=2,\n",
      "                     weights='distance') 0.717 0.053\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=50, n_neighbors=2,\n",
      "                     weights='distance') 0.717 0.053\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=60, n_neighbors=2,\n",
      "                     weights='distance') 0.717 0.053\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=70, n_neighbors=2,\n",
      "                     weights='distance') 0.717 0.053\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=80, n_neighbors=2,\n",
      "                     weights='distance') 0.717 0.053\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=10, n_neighbors=2,\n",
      "                     weights='distance') 0.717 0.053\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=20, n_neighbors=2,\n",
      "                     weights='distance') 0.717 0.053\n",
      "KNeighborsClassifier(algorithm='kd_tree', n_neighbors=2, weights='distance') 0.717 0.053\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=40, n_neighbors=2,\n",
      "                     weights='distance') 0.717 0.053\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=50, n_neighbors=2,\n",
      "                     weights='distance') 0.717 0.053\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=60, n_neighbors=2,\n",
      "                     weights='distance') 0.717 0.053\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=70, n_neighbors=2,\n",
      "                     weights='distance') 0.717 0.053\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=80, n_neighbors=2,\n",
      "                     weights='distance') 0.717 0.053\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=10, n_neighbors=2,\n",
      "                     weights='distance') 0.717 0.053\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=20, n_neighbors=2,\n",
      "                     weights='distance') 0.717 0.053\n",
      "KNeighborsClassifier(algorithm='brute', n_neighbors=2, weights='distance') 0.717 0.053\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=40, n_neighbors=2,\n",
      "                     weights='distance') 0.717 0.053\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=50, n_neighbors=2,\n",
      "                     weights='distance') 0.717 0.053\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=60, n_neighbors=2,\n",
      "                     weights='distance') 0.717 0.053\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=70, n_neighbors=2,\n",
      "                     weights='distance') 0.717 0.053\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=80, n_neighbors=2,\n",
      "                     weights='distance') 0.717 0.053\n",
      "KNeighborsClassifier(leaf_size=10, n_neighbors=3) 0.731 0.048\n",
      "KNeighborsClassifier(leaf_size=20, n_neighbors=3) 0.731 0.048\n",
      "KNeighborsClassifier(n_neighbors=3) 0.731 0.048\n",
      "KNeighborsClassifier(leaf_size=40, n_neighbors=3) 0.731 0.048\n",
      "KNeighborsClassifier(leaf_size=50, n_neighbors=3) 0.731 0.048\n",
      "KNeighborsClassifier(leaf_size=60, n_neighbors=3) 0.731 0.048\n",
      "KNeighborsClassifier(leaf_size=70, n_neighbors=3) 0.731 0.048\n",
      "KNeighborsClassifier(leaf_size=80, n_neighbors=3) 0.731 0.048\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=10, n_neighbors=3) 0.731 0.048\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=20, n_neighbors=3) 0.731 0.048\n",
      "KNeighborsClassifier(algorithm='ball_tree', n_neighbors=3) 0.731 0.048\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=40, n_neighbors=3) 0.731 0.048\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=50, n_neighbors=3) 0.731 0.048\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=60, n_neighbors=3) 0.731 0.048\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=70, n_neighbors=3) 0.731 0.048\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=80, n_neighbors=3) 0.731 0.048\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=10, n_neighbors=3) 0.731 0.048\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=20, n_neighbors=3) 0.731 0.048\n",
      "KNeighborsClassifier(algorithm='kd_tree', n_neighbors=3) 0.731 0.048\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=40, n_neighbors=3) 0.731 0.048\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=50, n_neighbors=3) 0.731 0.048\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=60, n_neighbors=3) 0.731 0.048\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=70, n_neighbors=3) 0.731 0.048\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=80, n_neighbors=3) 0.731 0.048\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=10, n_neighbors=3) 0.731 0.048\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=20, n_neighbors=3) 0.731 0.048\n",
      "KNeighborsClassifier(algorithm='brute', n_neighbors=3) 0.731 0.048\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=40, n_neighbors=3) 0.731 0.048\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=50, n_neighbors=3) 0.731 0.048\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=60, n_neighbors=3) 0.731 0.048\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=70, n_neighbors=3) 0.731 0.048\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=80, n_neighbors=3) 0.731 0.048\n",
      "KNeighborsClassifier(leaf_size=10, n_neighbors=3, weights='distance') 0.737 0.052\n",
      "KNeighborsClassifier(leaf_size=20, n_neighbors=3, weights='distance') 0.737 0.052\n",
      "KNeighborsClassifier(n_neighbors=3, weights='distance') 0.737 0.052\n",
      "KNeighborsClassifier(leaf_size=40, n_neighbors=3, weights='distance') 0.737 0.052\n",
      "KNeighborsClassifier(leaf_size=50, n_neighbors=3, weights='distance') 0.737 0.052\n",
      "KNeighborsClassifier(leaf_size=60, n_neighbors=3, weights='distance') 0.737 0.052\n",
      "KNeighborsClassifier(leaf_size=70, n_neighbors=3, weights='distance') 0.737 0.052\n",
      "KNeighborsClassifier(leaf_size=80, n_neighbors=3, weights='distance') 0.737 0.052\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=10, n_neighbors=3,\n",
      "                     weights='distance') 0.737 0.052\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=20, n_neighbors=3,\n",
      "                     weights='distance') 0.737 0.052\n",
      "KNeighborsClassifier(algorithm='ball_tree', n_neighbors=3, weights='distance') 0.737 0.052\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=40, n_neighbors=3,\n",
      "                     weights='distance') 0.737 0.052\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=50, n_neighbors=3,\n",
      "                     weights='distance') 0.737 0.052\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=60, n_neighbors=3,\n",
      "                     weights='distance') 0.737 0.052\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=70, n_neighbors=3,\n",
      "                     weights='distance') 0.737 0.052\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=80, n_neighbors=3,\n",
      "                     weights='distance') 0.737 0.052\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=10, n_neighbors=3,\n",
      "                     weights='distance') 0.737 0.052\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=20, n_neighbors=3,\n",
      "                     weights='distance') 0.737 0.052\n",
      "KNeighborsClassifier(algorithm='kd_tree', n_neighbors=3, weights='distance') 0.737 0.052\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=40, n_neighbors=3,\n",
      "                     weights='distance') 0.737 0.052\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=50, n_neighbors=3,\n",
      "                     weights='distance') 0.737 0.052\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=60, n_neighbors=3,\n",
      "                     weights='distance') 0.737 0.052\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=70, n_neighbors=3,\n",
      "                     weights='distance') 0.737 0.052\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=80, n_neighbors=3,\n",
      "                     weights='distance') 0.737 0.052\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=10, n_neighbors=3,\n",
      "                     weights='distance') 0.737 0.052\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=20, n_neighbors=3,\n",
      "                     weights='distance') 0.737 0.052\n",
      "KNeighborsClassifier(algorithm='brute', n_neighbors=3, weights='distance') 0.737 0.052\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=40, n_neighbors=3,\n",
      "                     weights='distance') 0.737 0.052\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=50, n_neighbors=3,\n",
      "                     weights='distance') 0.737 0.052\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=60, n_neighbors=3,\n",
      "                     weights='distance') 0.737 0.052\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=70, n_neighbors=3,\n",
      "                     weights='distance') 0.737 0.052\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=80, n_neighbors=3,\n",
      "                     weights='distance') 0.737 0.052\n",
      "KNeighborsClassifier(leaf_size=10) 0.727 0.038\n",
      "KNeighborsClassifier(leaf_size=20) 0.727 0.038\n",
      "KNeighborsClassifier() 0.727 0.038\n",
      "KNeighborsClassifier(leaf_size=40) 0.727 0.038\n",
      "KNeighborsClassifier(leaf_size=50) 0.727 0.038\n",
      "KNeighborsClassifier(leaf_size=60) 0.727 0.038\n",
      "KNeighborsClassifier(leaf_size=70) 0.727 0.038\n",
      "KNeighborsClassifier(leaf_size=80) 0.727 0.038\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=10) 0.727 0.035\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=20) 0.727 0.035\n",
      "KNeighborsClassifier(algorithm='ball_tree') 0.727 0.035\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=40) 0.727 0.035\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=50) 0.727 0.035\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=60) 0.727 0.035\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=70) 0.727 0.035\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=80) 0.727 0.035\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=10) 0.727 0.035\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=20) 0.727 0.035\n",
      "KNeighborsClassifier(algorithm='kd_tree') 0.727 0.035\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=40) 0.727 0.035\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=50) 0.727 0.035\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=60) 0.727 0.035\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=70) 0.727 0.035\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=80) 0.727 0.035\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=10) 0.727 0.038\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=20) 0.727 0.038\n",
      "KNeighborsClassifier(algorithm='brute') 0.727 0.038\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=40) 0.727 0.038\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=50) 0.727 0.038\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=60) 0.727 0.038\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=70) 0.727 0.038\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=80) 0.727 0.038\n",
      "KNeighborsClassifier(leaf_size=10, weights='distance') 0.729 0.04\n",
      "KNeighborsClassifier(leaf_size=20, weights='distance') 0.729 0.04\n",
      "KNeighborsClassifier(weights='distance') 0.729 0.04\n",
      "KNeighborsClassifier(leaf_size=40, weights='distance') 0.729 0.04\n",
      "KNeighborsClassifier(leaf_size=50, weights='distance') 0.729 0.04\n",
      "KNeighborsClassifier(leaf_size=60, weights='distance') 0.729 0.04\n",
      "KNeighborsClassifier(leaf_size=70, weights='distance') 0.729 0.04\n",
      "KNeighborsClassifier(leaf_size=80, weights='distance') 0.729 0.04\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=10, weights='distance') 0.729 0.037\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=20, weights='distance') 0.729 0.037\n",
      "KNeighborsClassifier(algorithm='ball_tree', weights='distance') 0.729 0.037\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=40, weights='distance') 0.729 0.037\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=50, weights='distance') 0.729 0.037\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=60, weights='distance') 0.729 0.037\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=70, weights='distance') 0.729 0.037\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=80, weights='distance') 0.729 0.037\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=10, weights='distance') 0.729 0.037\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=20, weights='distance') 0.729 0.037\n",
      "KNeighborsClassifier(algorithm='kd_tree', weights='distance') 0.729 0.037\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=40, weights='distance') 0.729 0.037\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=50, weights='distance') 0.729 0.037\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=60, weights='distance') 0.729 0.037\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=70, weights='distance') 0.729 0.037\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=80, weights='distance') 0.729 0.037\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=10, weights='distance') 0.729 0.04\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=20, weights='distance') 0.729 0.04\n",
      "KNeighborsClassifier(algorithm='brute', weights='distance') 0.729 0.04\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=40, weights='distance') 0.729 0.04\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=50, weights='distance') 0.729 0.04\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=60, weights='distance') 0.729 0.04\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=70, weights='distance') 0.729 0.04\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=80, weights='distance') 0.729 0.04\n",
      "KNeighborsClassifier(leaf_size=10, n_neighbors=7) 0.719 0.047\n",
      "KNeighborsClassifier(leaf_size=20, n_neighbors=7) 0.719 0.047\n",
      "KNeighborsClassifier(n_neighbors=7) 0.719 0.047\n",
      "KNeighborsClassifier(leaf_size=40, n_neighbors=7) 0.719 0.047\n",
      "KNeighborsClassifier(leaf_size=50, n_neighbors=7) 0.719 0.047\n",
      "KNeighborsClassifier(leaf_size=60, n_neighbors=7) 0.719 0.047\n",
      "KNeighborsClassifier(leaf_size=70, n_neighbors=7) 0.719 0.047\n",
      "KNeighborsClassifier(leaf_size=80, n_neighbors=7) 0.719 0.047\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=10, n_neighbors=7) 0.719 0.047\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=20, n_neighbors=7) 0.719 0.047\n",
      "KNeighborsClassifier(algorithm='ball_tree', n_neighbors=7) 0.719 0.047\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=40, n_neighbors=7) 0.719 0.047\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=50, n_neighbors=7) 0.719 0.047\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=60, n_neighbors=7) 0.719 0.047\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=70, n_neighbors=7) 0.719 0.047\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=80, n_neighbors=7) 0.719 0.047\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=10, n_neighbors=7) 0.719 0.047\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=20, n_neighbors=7) 0.719 0.047\n",
      "KNeighborsClassifier(algorithm='kd_tree', n_neighbors=7) 0.719 0.047\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=40, n_neighbors=7) 0.719 0.047\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=50, n_neighbors=7) 0.719 0.047\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=60, n_neighbors=7) 0.719 0.047\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=70, n_neighbors=7) 0.719 0.047\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=80, n_neighbors=7) 0.719 0.047\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=10, n_neighbors=7) 0.719 0.047\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=20, n_neighbors=7) 0.719 0.047\n",
      "KNeighborsClassifier(algorithm='brute', n_neighbors=7) 0.719 0.047\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=40, n_neighbors=7) 0.719 0.047\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=50, n_neighbors=7) 0.719 0.047\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=60, n_neighbors=7) 0.719 0.047\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=70, n_neighbors=7) 0.719 0.047\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=80, n_neighbors=7) 0.719 0.047\n",
      "KNeighborsClassifier(leaf_size=10, n_neighbors=7, weights='distance') 0.724 0.053\n",
      "KNeighborsClassifier(leaf_size=20, n_neighbors=7, weights='distance') 0.724 0.053\n",
      "KNeighborsClassifier(n_neighbors=7, weights='distance') 0.724 0.053\n",
      "KNeighborsClassifier(leaf_size=40, n_neighbors=7, weights='distance') 0.724 0.053\n",
      "KNeighborsClassifier(leaf_size=50, n_neighbors=7, weights='distance') 0.724 0.053\n",
      "KNeighborsClassifier(leaf_size=60, n_neighbors=7, weights='distance') 0.724 0.053\n",
      "KNeighborsClassifier(leaf_size=70, n_neighbors=7, weights='distance') 0.724 0.053\n",
      "KNeighborsClassifier(leaf_size=80, n_neighbors=7, weights='distance') 0.724 0.053\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=10, n_neighbors=7,\n",
      "                     weights='distance') 0.724 0.053\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=20, n_neighbors=7,\n",
      "                     weights='distance') 0.724 0.053\n",
      "KNeighborsClassifier(algorithm='ball_tree', n_neighbors=7, weights='distance') 0.724 0.053\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=40, n_neighbors=7,\n",
      "                     weights='distance') 0.724 0.053\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=50, n_neighbors=7,\n",
      "                     weights='distance') 0.724 0.053\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=60, n_neighbors=7,\n",
      "                     weights='distance') 0.724 0.053\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=70, n_neighbors=7,\n",
      "                     weights='distance') 0.724 0.053\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=80, n_neighbors=7,\n",
      "                     weights='distance') 0.724 0.053\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=10, n_neighbors=7,\n",
      "                     weights='distance') 0.724 0.053\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=20, n_neighbors=7,\n",
      "                     weights='distance') 0.724 0.053\n",
      "KNeighborsClassifier(algorithm='kd_tree', n_neighbors=7, weights='distance') 0.724 0.053\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=40, n_neighbors=7,\n",
      "                     weights='distance') 0.724 0.053\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=50, n_neighbors=7,\n",
      "                     weights='distance') 0.724 0.053\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=60, n_neighbors=7,\n",
      "                     weights='distance') 0.724 0.053\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=70, n_neighbors=7,\n",
      "                     weights='distance') 0.724 0.053\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=80, n_neighbors=7,\n",
      "                     weights='distance') 0.724 0.053\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=10, n_neighbors=7,\n",
      "                     weights='distance') 0.724 0.053\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=20, n_neighbors=7,\n",
      "                     weights='distance') 0.724 0.053\n",
      "KNeighborsClassifier(algorithm='brute', n_neighbors=7, weights='distance') 0.724 0.053\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=40, n_neighbors=7,\n",
      "                     weights='distance') 0.724 0.053\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=50, n_neighbors=7,\n",
      "                     weights='distance') 0.724 0.053\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=60, n_neighbors=7,\n",
      "                     weights='distance') 0.724 0.053\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=70, n_neighbors=7,\n",
      "                     weights='distance') 0.724 0.053\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=80, n_neighbors=7,\n",
      "                     weights='distance') 0.724 0.053\n",
      "KNeighborsClassifier(leaf_size=10, n_neighbors=11) 0.721 0.051\n",
      "KNeighborsClassifier(leaf_size=20, n_neighbors=11) 0.721 0.051\n",
      "KNeighborsClassifier(n_neighbors=11) 0.721 0.051\n",
      "KNeighborsClassifier(leaf_size=40, n_neighbors=11) 0.721 0.051\n",
      "KNeighborsClassifier(leaf_size=50, n_neighbors=11) 0.721 0.051\n",
      "KNeighborsClassifier(leaf_size=60, n_neighbors=11) 0.721 0.051\n",
      "KNeighborsClassifier(leaf_size=70, n_neighbors=11) 0.721 0.051\n",
      "KNeighborsClassifier(leaf_size=80, n_neighbors=11) 0.721 0.051\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=10, n_neighbors=11) 0.72 0.052\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=20, n_neighbors=11) 0.72 0.052\n",
      "KNeighborsClassifier(algorithm='ball_tree', n_neighbors=11) 0.72 0.052\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=40, n_neighbors=11) 0.72 0.052\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=50, n_neighbors=11) 0.72 0.052\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=60, n_neighbors=11) 0.72 0.052\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=70, n_neighbors=11) 0.72 0.052\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=80, n_neighbors=11) 0.72 0.052\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=10, n_neighbors=11) 0.721 0.051\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=20, n_neighbors=11) 0.721 0.051\n",
      "KNeighborsClassifier(algorithm='kd_tree', n_neighbors=11) 0.72 0.052\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=40, n_neighbors=11) 0.72 0.052\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=50, n_neighbors=11) 0.72 0.052\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=60, n_neighbors=11) 0.72 0.052\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=70, n_neighbors=11) 0.72 0.052\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=80, n_neighbors=11) 0.72 0.052\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=10, n_neighbors=11) 0.721 0.051\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=20, n_neighbors=11) 0.721 0.051\n",
      "KNeighborsClassifier(algorithm='brute', n_neighbors=11) 0.721 0.051\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=40, n_neighbors=11) 0.721 0.051\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=50, n_neighbors=11) 0.721 0.051\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=60, n_neighbors=11) 0.721 0.051\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=70, n_neighbors=11) 0.721 0.051\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=80, n_neighbors=11) 0.721 0.051\n",
      "KNeighborsClassifier(leaf_size=10, n_neighbors=11, weights='distance') 0.723 0.052\n",
      "KNeighborsClassifier(leaf_size=20, n_neighbors=11, weights='distance') 0.723 0.052\n",
      "KNeighborsClassifier(n_neighbors=11, weights='distance') 0.723 0.052\n",
      "KNeighborsClassifier(leaf_size=40, n_neighbors=11, weights='distance') 0.723 0.052\n",
      "KNeighborsClassifier(leaf_size=50, n_neighbors=11, weights='distance') 0.723 0.052\n",
      "KNeighborsClassifier(leaf_size=60, n_neighbors=11, weights='distance') 0.723 0.052\n",
      "KNeighborsClassifier(leaf_size=70, n_neighbors=11, weights='distance') 0.723 0.052\n",
      "KNeighborsClassifier(leaf_size=80, n_neighbors=11, weights='distance') 0.723 0.052\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=10, n_neighbors=11,\n",
      "                     weights='distance') 0.722 0.053\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=20, n_neighbors=11,\n",
      "                     weights='distance') 0.722 0.053\n",
      "KNeighborsClassifier(algorithm='ball_tree', n_neighbors=11, weights='distance') 0.722 0.053\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=40, n_neighbors=11,\n",
      "                     weights='distance') 0.722 0.053\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=50, n_neighbors=11,\n",
      "                     weights='distance') 0.722 0.053\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=60, n_neighbors=11,\n",
      "                     weights='distance') 0.722 0.053\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=70, n_neighbors=11,\n",
      "                     weights='distance') 0.722 0.053\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=80, n_neighbors=11,\n",
      "                     weights='distance') 0.722 0.053\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=10, n_neighbors=11,\n",
      "                     weights='distance') 0.723 0.052\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=20, n_neighbors=11,\n",
      "                     weights='distance') 0.723 0.052\n",
      "KNeighborsClassifier(algorithm='kd_tree', n_neighbors=11, weights='distance') 0.722 0.053\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=40, n_neighbors=11,\n",
      "                     weights='distance') 0.722 0.053\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=50, n_neighbors=11,\n",
      "                     weights='distance') 0.722 0.053\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=60, n_neighbors=11,\n",
      "                     weights='distance') 0.722 0.053\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=70, n_neighbors=11,\n",
      "                     weights='distance') 0.722 0.053\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=80, n_neighbors=11,\n",
      "                     weights='distance') 0.722 0.053\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=10, n_neighbors=11,\n",
      "                     weights='distance') 0.723 0.052\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=20, n_neighbors=11,\n",
      "                     weights='distance') 0.723 0.052\n",
      "KNeighborsClassifier(algorithm='brute', n_neighbors=11, weights='distance') 0.723 0.052\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=40, n_neighbors=11,\n",
      "                     weights='distance') 0.723 0.052\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=50, n_neighbors=11,\n",
      "                     weights='distance') 0.723 0.052\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=60, n_neighbors=11,\n",
      "                     weights='distance') 0.723 0.052\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=70, n_neighbors=11,\n",
      "                     weights='distance') 0.723 0.052\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=80, n_neighbors=11,\n",
      "                     weights='distance') 0.723 0.052\n",
      "KNeighborsClassifier(leaf_size=10, n_neighbors=13) 0.729 0.042\n",
      "KNeighborsClassifier(leaf_size=20, n_neighbors=13) 0.729 0.042\n",
      "KNeighborsClassifier(n_neighbors=13) 0.729 0.042\n",
      "KNeighborsClassifier(leaf_size=40, n_neighbors=13) 0.729 0.042\n",
      "KNeighborsClassifier(leaf_size=50, n_neighbors=13) 0.729 0.042\n",
      "KNeighborsClassifier(leaf_size=60, n_neighbors=13) 0.729 0.042\n",
      "KNeighborsClassifier(leaf_size=70, n_neighbors=13) 0.729 0.042\n",
      "KNeighborsClassifier(leaf_size=80, n_neighbors=13) 0.729 0.042\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=10, n_neighbors=13) 0.729 0.042\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=20, n_neighbors=13) 0.729 0.042\n",
      "KNeighborsClassifier(algorithm='ball_tree', n_neighbors=13) 0.729 0.042\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=40, n_neighbors=13) 0.729 0.042\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=50, n_neighbors=13) 0.729 0.042\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=60, n_neighbors=13) 0.729 0.042\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=70, n_neighbors=13) 0.729 0.042\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=80, n_neighbors=13) 0.729 0.042\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=10, n_neighbors=13) 0.729 0.042\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=20, n_neighbors=13) 0.729 0.042\n",
      "KNeighborsClassifier(algorithm='kd_tree', n_neighbors=13) 0.729 0.042\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=40, n_neighbors=13) 0.729 0.042\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=50, n_neighbors=13) 0.729 0.042\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=60, n_neighbors=13) 0.729 0.042\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=70, n_neighbors=13) 0.729 0.042\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=80, n_neighbors=13) 0.729 0.042\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=10, n_neighbors=13) 0.729 0.042\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=20, n_neighbors=13) 0.729 0.042\n",
      "KNeighborsClassifier(algorithm='brute', n_neighbors=13) 0.729 0.042\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=40, n_neighbors=13) 0.729 0.042\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=50, n_neighbors=13) 0.729 0.042\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=60, n_neighbors=13) 0.729 0.042\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=70, n_neighbors=13) 0.729 0.042\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=80, n_neighbors=13) 0.729 0.042\n",
      "KNeighborsClassifier(leaf_size=10, n_neighbors=13, weights='distance') 0.735 0.037\n",
      "KNeighborsClassifier(leaf_size=20, n_neighbors=13, weights='distance') 0.735 0.037\n",
      "KNeighborsClassifier(n_neighbors=13, weights='distance') 0.735 0.037\n",
      "KNeighborsClassifier(leaf_size=40, n_neighbors=13, weights='distance') 0.735 0.037\n",
      "KNeighborsClassifier(leaf_size=50, n_neighbors=13, weights='distance') 0.735 0.037\n",
      "KNeighborsClassifier(leaf_size=60, n_neighbors=13, weights='distance') 0.735 0.037\n",
      "KNeighborsClassifier(leaf_size=70, n_neighbors=13, weights='distance') 0.735 0.037\n",
      "KNeighborsClassifier(leaf_size=80, n_neighbors=13, weights='distance') 0.735 0.037\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=10, n_neighbors=13,\n",
      "                     weights='distance') 0.735 0.037\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=20, n_neighbors=13,\n",
      "                     weights='distance') 0.735 0.037\n",
      "KNeighborsClassifier(algorithm='ball_tree', n_neighbors=13, weights='distance') 0.735 0.037\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=40, n_neighbors=13,\n",
      "                     weights='distance') 0.735 0.037\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=50, n_neighbors=13,\n",
      "                     weights='distance') 0.735 0.037\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=60, n_neighbors=13,\n",
      "                     weights='distance') 0.735 0.037\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=70, n_neighbors=13,\n",
      "                     weights='distance') 0.735 0.037\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=80, n_neighbors=13,\n",
      "                     weights='distance') 0.735 0.037\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=10, n_neighbors=13,\n",
      "                     weights='distance') 0.735 0.037\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=20, n_neighbors=13,\n",
      "                     weights='distance') 0.735 0.037\n",
      "KNeighborsClassifier(algorithm='kd_tree', n_neighbors=13, weights='distance') 0.735 0.037\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=40, n_neighbors=13,\n",
      "                     weights='distance') 0.735 0.037\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=50, n_neighbors=13,\n",
      "                     weights='distance') 0.735 0.037\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=60, n_neighbors=13,\n",
      "                     weights='distance') 0.735 0.037\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=70, n_neighbors=13,\n",
      "                     weights='distance') 0.735 0.037\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=80, n_neighbors=13,\n",
      "                     weights='distance') 0.735 0.037\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=10, n_neighbors=13,\n",
      "                     weights='distance') 0.735 0.037\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=20, n_neighbors=13,\n",
      "                     weights='distance') 0.735 0.037\n",
      "KNeighborsClassifier(algorithm='brute', n_neighbors=13, weights='distance') 0.735 0.037\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=40, n_neighbors=13,\n",
      "                     weights='distance') 0.735 0.037\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=50, n_neighbors=13,\n",
      "                     weights='distance') 0.735 0.037\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=60, n_neighbors=13,\n",
      "                     weights='distance') 0.735 0.037\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=70, n_neighbors=13,\n",
      "                     weights='distance') 0.735 0.037\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=80, n_neighbors=13,\n",
      "                     weights='distance') 0.735 0.037\n",
      "KNeighborsClassifier(leaf_size=10, n_neighbors=17) 0.716 0.053\n",
      "KNeighborsClassifier(leaf_size=20, n_neighbors=17) 0.716 0.053\n",
      "KNeighborsClassifier(n_neighbors=17) 0.716 0.053\n",
      "KNeighborsClassifier(leaf_size=40, n_neighbors=17) 0.716 0.053\n",
      "KNeighborsClassifier(leaf_size=50, n_neighbors=17) 0.716 0.053\n",
      "KNeighborsClassifier(leaf_size=60, n_neighbors=17) 0.716 0.053\n",
      "KNeighborsClassifier(leaf_size=70, n_neighbors=17) 0.716 0.053\n",
      "KNeighborsClassifier(leaf_size=80, n_neighbors=17) 0.716 0.053\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=10, n_neighbors=17) 0.717 0.054\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=20, n_neighbors=17) 0.717 0.054\n",
      "KNeighborsClassifier(algorithm='ball_tree', n_neighbors=17) 0.717 0.054\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=40, n_neighbors=17) 0.717 0.054\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=50, n_neighbors=17) 0.717 0.054\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=60, n_neighbors=17) 0.717 0.054\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=70, n_neighbors=17) 0.717 0.054\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=80, n_neighbors=17) 0.717 0.054\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=10, n_neighbors=17) 0.717 0.054\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=20, n_neighbors=17) 0.717 0.054\n",
      "KNeighborsClassifier(algorithm='kd_tree', n_neighbors=17) 0.717 0.054\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=40, n_neighbors=17) 0.717 0.054\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=50, n_neighbors=17) 0.717 0.054\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=60, n_neighbors=17) 0.717 0.054\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=70, n_neighbors=17) 0.717 0.054\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=80, n_neighbors=17) 0.717 0.054\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=10, n_neighbors=17) 0.716 0.053\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=20, n_neighbors=17) 0.716 0.053\n",
      "KNeighborsClassifier(algorithm='brute', n_neighbors=17) 0.716 0.053\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=40, n_neighbors=17) 0.716 0.053\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=50, n_neighbors=17) 0.716 0.053\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=60, n_neighbors=17) 0.716 0.053\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=70, n_neighbors=17) 0.716 0.053\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=80, n_neighbors=17) 0.716 0.053\n",
      "KNeighborsClassifier(leaf_size=10, n_neighbors=17, weights='distance') 0.725 0.055\n",
      "KNeighborsClassifier(leaf_size=20, n_neighbors=17, weights='distance') 0.725 0.055\n",
      "KNeighborsClassifier(n_neighbors=17, weights='distance') 0.725 0.055\n",
      "KNeighborsClassifier(leaf_size=40, n_neighbors=17, weights='distance') 0.725 0.055\n",
      "KNeighborsClassifier(leaf_size=50, n_neighbors=17, weights='distance') 0.725 0.055\n",
      "KNeighborsClassifier(leaf_size=60, n_neighbors=17, weights='distance') 0.725 0.055\n",
      "KNeighborsClassifier(leaf_size=70, n_neighbors=17, weights='distance') 0.725 0.055\n",
      "KNeighborsClassifier(leaf_size=80, n_neighbors=17, weights='distance') 0.725 0.055\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=10, n_neighbors=17,\n",
      "                     weights='distance') 0.726 0.056\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=20, n_neighbors=17,\n",
      "                     weights='distance') 0.726 0.056\n",
      "KNeighborsClassifier(algorithm='ball_tree', n_neighbors=17, weights='distance') 0.726 0.056\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=40, n_neighbors=17,\n",
      "                     weights='distance') 0.726 0.056\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=50, n_neighbors=17,\n",
      "                     weights='distance') 0.726 0.056\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=60, n_neighbors=17,\n",
      "                     weights='distance') 0.726 0.056\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=70, n_neighbors=17,\n",
      "                     weights='distance') 0.726 0.056\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=80, n_neighbors=17,\n",
      "                     weights='distance') 0.726 0.056\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=10, n_neighbors=17,\n",
      "                     weights='distance') 0.726 0.056\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=20, n_neighbors=17,\n",
      "                     weights='distance') 0.726 0.056\n",
      "KNeighborsClassifier(algorithm='kd_tree', n_neighbors=17, weights='distance') 0.726 0.056\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=40, n_neighbors=17,\n",
      "                     weights='distance') 0.726 0.056\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=50, n_neighbors=17,\n",
      "                     weights='distance') 0.726 0.056\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=60, n_neighbors=17,\n",
      "                     weights='distance') 0.726 0.056\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=70, n_neighbors=17,\n",
      "                     weights='distance') 0.726 0.056\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=80, n_neighbors=17,\n",
      "                     weights='distance') 0.726 0.056\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=10, n_neighbors=17,\n",
      "                     weights='distance') 0.725 0.055\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=20, n_neighbors=17,\n",
      "                     weights='distance') 0.725 0.055\n",
      "KNeighborsClassifier(algorithm='brute', n_neighbors=17, weights='distance') 0.725 0.055\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=40, n_neighbors=17,\n",
      "                     weights='distance') 0.725 0.055\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=50, n_neighbors=17,\n",
      "                     weights='distance') 0.725 0.055\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=60, n_neighbors=17,\n",
      "                     weights='distance') 0.725 0.055\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=70, n_neighbors=17,\n",
      "                     weights='distance') 0.725 0.055\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=80, n_neighbors=17,\n",
      "                     weights='distance') 0.725 0.055\n",
      "KNeighborsClassifier(leaf_size=10, n_neighbors=19) 0.721 0.044\n",
      "KNeighborsClassifier(leaf_size=20, n_neighbors=19) 0.721 0.044\n",
      "KNeighborsClassifier(n_neighbors=19) 0.721 0.044\n",
      "KNeighborsClassifier(leaf_size=40, n_neighbors=19) 0.721 0.044\n",
      "KNeighborsClassifier(leaf_size=50, n_neighbors=19) 0.721 0.044\n",
      "KNeighborsClassifier(leaf_size=60, n_neighbors=19) 0.721 0.044\n",
      "KNeighborsClassifier(leaf_size=70, n_neighbors=19) 0.721 0.044\n",
      "KNeighborsClassifier(leaf_size=80, n_neighbors=19) 0.721 0.044\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=10, n_neighbors=19) 0.721 0.044\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=20, n_neighbors=19) 0.721 0.044\n",
      "KNeighborsClassifier(algorithm='ball_tree', n_neighbors=19) 0.721 0.044\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=40, n_neighbors=19) 0.721 0.044\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=50, n_neighbors=19) 0.721 0.044\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=60, n_neighbors=19) 0.721 0.044\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=70, n_neighbors=19) 0.721 0.044\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=80, n_neighbors=19) 0.721 0.044\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=10, n_neighbors=19) 0.721 0.044\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=20, n_neighbors=19) 0.721 0.044\n",
      "KNeighborsClassifier(algorithm='kd_tree', n_neighbors=19) 0.721 0.044\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=40, n_neighbors=19) 0.721 0.044\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=50, n_neighbors=19) 0.721 0.044\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=60, n_neighbors=19) 0.721 0.044\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=70, n_neighbors=19) 0.721 0.044\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=80, n_neighbors=19) 0.721 0.044\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=10, n_neighbors=19) 0.721 0.044\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=20, n_neighbors=19) 0.721 0.044\n",
      "KNeighborsClassifier(algorithm='brute', n_neighbors=19) 0.721 0.044\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=40, n_neighbors=19) 0.721 0.044\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=50, n_neighbors=19) 0.721 0.044\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=60, n_neighbors=19) 0.721 0.044\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=70, n_neighbors=19) 0.721 0.044\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=80, n_neighbors=19) 0.721 0.044\n",
      "KNeighborsClassifier(leaf_size=10, n_neighbors=19, weights='distance') 0.733 0.04\n",
      "KNeighborsClassifier(leaf_size=20, n_neighbors=19, weights='distance') 0.733 0.04\n",
      "KNeighborsClassifier(n_neighbors=19, weights='distance') 0.733 0.04\n",
      "KNeighborsClassifier(leaf_size=40, n_neighbors=19, weights='distance') 0.733 0.04\n",
      "KNeighborsClassifier(leaf_size=50, n_neighbors=19, weights='distance') 0.733 0.04\n",
      "KNeighborsClassifier(leaf_size=60, n_neighbors=19, weights='distance') 0.733 0.04\n",
      "KNeighborsClassifier(leaf_size=70, n_neighbors=19, weights='distance') 0.733 0.04\n",
      "KNeighborsClassifier(leaf_size=80, n_neighbors=19, weights='distance') 0.733 0.04\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=10, n_neighbors=19,\n",
      "                     weights='distance') 0.733 0.04\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=20, n_neighbors=19,\n",
      "                     weights='distance') 0.733 0.04\n",
      "KNeighborsClassifier(algorithm='ball_tree', n_neighbors=19, weights='distance') 0.733 0.04\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=40, n_neighbors=19,\n",
      "                     weights='distance') 0.733 0.04\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=50, n_neighbors=19,\n",
      "                     weights='distance') 0.733 0.04\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=60, n_neighbors=19,\n",
      "                     weights='distance') 0.733 0.04\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=70, n_neighbors=19,\n",
      "                     weights='distance') 0.733 0.04\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=80, n_neighbors=19,\n",
      "                     weights='distance') 0.733 0.04\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=10, n_neighbors=19,\n",
      "                     weights='distance') 0.733 0.04\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=20, n_neighbors=19,\n",
      "                     weights='distance') 0.733 0.04\n",
      "KNeighborsClassifier(algorithm='kd_tree', n_neighbors=19, weights='distance') 0.733 0.04\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=40, n_neighbors=19,\n",
      "                     weights='distance') 0.733 0.04\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=50, n_neighbors=19,\n",
      "                     weights='distance') 0.733 0.04\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=60, n_neighbors=19,\n",
      "                     weights='distance') 0.733 0.04\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=70, n_neighbors=19,\n",
      "                     weights='distance') 0.733 0.04\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=80, n_neighbors=19,\n",
      "                     weights='distance') 0.733 0.04\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=10, n_neighbors=19,\n",
      "                     weights='distance') 0.733 0.04\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=20, n_neighbors=19,\n",
      "                     weights='distance') 0.733 0.04\n",
      "KNeighborsClassifier(algorithm='brute', n_neighbors=19, weights='distance') 0.733 0.04\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=40, n_neighbors=19,\n",
      "                     weights='distance') 0.733 0.04\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=50, n_neighbors=19,\n",
      "                     weights='distance') 0.733 0.04\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=60, n_neighbors=19,\n",
      "                     weights='distance') 0.733 0.04\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=70, n_neighbors=19,\n",
      "                     weights='distance') 0.733 0.04\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=80, n_neighbors=19,\n",
      "                     weights='distance') 0.733 0.04\n",
      "KNeighborsClassifier(leaf_size=10, n_neighbors=23) 0.7 0.037\n",
      "KNeighborsClassifier(leaf_size=20, n_neighbors=23) 0.7 0.037\n",
      "KNeighborsClassifier(n_neighbors=23) 0.7 0.037\n",
      "KNeighborsClassifier(leaf_size=40, n_neighbors=23) 0.7 0.037\n",
      "KNeighborsClassifier(leaf_size=50, n_neighbors=23) 0.7 0.037\n",
      "KNeighborsClassifier(leaf_size=60, n_neighbors=23) 0.7 0.037\n",
      "KNeighborsClassifier(leaf_size=70, n_neighbors=23) 0.7 0.037\n",
      "KNeighborsClassifier(leaf_size=80, n_neighbors=23) 0.7 0.037\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=10, n_neighbors=23) 0.7 0.037\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=20, n_neighbors=23) 0.7 0.037\n",
      "KNeighborsClassifier(algorithm='ball_tree', n_neighbors=23) 0.7 0.037\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=40, n_neighbors=23) 0.7 0.037\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=50, n_neighbors=23) 0.7 0.037\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=60, n_neighbors=23) 0.7 0.037\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=70, n_neighbors=23) 0.7 0.037\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=80, n_neighbors=23) 0.7 0.037\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=10, n_neighbors=23) 0.7 0.037\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=20, n_neighbors=23) 0.7 0.037\n",
      "KNeighborsClassifier(algorithm='kd_tree', n_neighbors=23) 0.7 0.037\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=40, n_neighbors=23) 0.7 0.037\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=50, n_neighbors=23) 0.7 0.037\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=60, n_neighbors=23) 0.7 0.037\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=70, n_neighbors=23) 0.7 0.037\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=80, n_neighbors=23) 0.7 0.037\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=10, n_neighbors=23) 0.7 0.037\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=20, n_neighbors=23) 0.7 0.037\n",
      "KNeighborsClassifier(algorithm='brute', n_neighbors=23) 0.7 0.037\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=40, n_neighbors=23) 0.7 0.037\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=50, n_neighbors=23) 0.7 0.037\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=60, n_neighbors=23) 0.7 0.037\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=70, n_neighbors=23) 0.7 0.037\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=80, n_neighbors=23) 0.7 0.037\n",
      "KNeighborsClassifier(leaf_size=10, n_neighbors=23, weights='distance') 0.712 0.039\n",
      "KNeighborsClassifier(leaf_size=20, n_neighbors=23, weights='distance') 0.712 0.039\n",
      "KNeighborsClassifier(n_neighbors=23, weights='distance') 0.712 0.039\n",
      "KNeighborsClassifier(leaf_size=40, n_neighbors=23, weights='distance') 0.712 0.039\n",
      "KNeighborsClassifier(leaf_size=50, n_neighbors=23, weights='distance') 0.712 0.039\n",
      "KNeighborsClassifier(leaf_size=60, n_neighbors=23, weights='distance') 0.712 0.039\n",
      "KNeighborsClassifier(leaf_size=70, n_neighbors=23, weights='distance') 0.712 0.039\n",
      "KNeighborsClassifier(leaf_size=80, n_neighbors=23, weights='distance') 0.712 0.039\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=10, n_neighbors=23,\n",
      "                     weights='distance') 0.712 0.039\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=20, n_neighbors=23,\n",
      "                     weights='distance') 0.712 0.039\n",
      "KNeighborsClassifier(algorithm='ball_tree', n_neighbors=23, weights='distance') 0.712 0.039\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=40, n_neighbors=23,\n",
      "                     weights='distance') 0.712 0.039\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=50, n_neighbors=23,\n",
      "                     weights='distance') 0.712 0.039\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=60, n_neighbors=23,\n",
      "                     weights='distance') 0.712 0.039\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=70, n_neighbors=23,\n",
      "                     weights='distance') 0.712 0.039\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=80, n_neighbors=23,\n",
      "                     weights='distance') 0.712 0.039\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=10, n_neighbors=23,\n",
      "                     weights='distance') 0.712 0.039\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=20, n_neighbors=23,\n",
      "                     weights='distance') 0.712 0.039\n",
      "KNeighborsClassifier(algorithm='kd_tree', n_neighbors=23, weights='distance') 0.712 0.039\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=40, n_neighbors=23,\n",
      "                     weights='distance') 0.712 0.039\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=50, n_neighbors=23,\n",
      "                     weights='distance') 0.712 0.039\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=60, n_neighbors=23,\n",
      "                     weights='distance') 0.712 0.039\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=70, n_neighbors=23,\n",
      "                     weights='distance') 0.712 0.039\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=80, n_neighbors=23,\n",
      "                     weights='distance') 0.712 0.039\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=10, n_neighbors=23,\n",
      "                     weights='distance') 0.712 0.039\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=20, n_neighbors=23,\n",
      "                     weights='distance') 0.712 0.039\n",
      "KNeighborsClassifier(algorithm='brute', n_neighbors=23, weights='distance') 0.712 0.039\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=40, n_neighbors=23,\n",
      "                     weights='distance') 0.712 0.039\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=50, n_neighbors=23,\n",
      "                     weights='distance') 0.712 0.039\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=60, n_neighbors=23,\n",
      "                     weights='distance') 0.712 0.039\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=70, n_neighbors=23,\n",
      "                     weights='distance') 0.712 0.039\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=80, n_neighbors=23,\n",
      "                     weights='distance') 0.712 0.039\n",
      "KNeighborsClassifier(leaf_size=10, n_neighbors=29) 0.707 0.047\n",
      "KNeighborsClassifier(leaf_size=20, n_neighbors=29) 0.707 0.047\n",
      "KNeighborsClassifier(n_neighbors=29) 0.707 0.047\n",
      "KNeighborsClassifier(leaf_size=40, n_neighbors=29) 0.707 0.047\n",
      "KNeighborsClassifier(leaf_size=50, n_neighbors=29) 0.707 0.047\n",
      "KNeighborsClassifier(leaf_size=60, n_neighbors=29) 0.707 0.047\n",
      "KNeighborsClassifier(leaf_size=70, n_neighbors=29) 0.707 0.047\n",
      "KNeighborsClassifier(leaf_size=80, n_neighbors=29) 0.707 0.047\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=10, n_neighbors=29) 0.708 0.048\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=20, n_neighbors=29) 0.708 0.048\n",
      "KNeighborsClassifier(algorithm='ball_tree', n_neighbors=29) 0.708 0.048\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=40, n_neighbors=29) 0.708 0.048\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=50, n_neighbors=29) 0.708 0.048\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=60, n_neighbors=29) 0.708 0.048\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=70, n_neighbors=29) 0.708 0.048\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=80, n_neighbors=29) 0.708 0.048\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=10, n_neighbors=29) 0.708 0.048\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=20, n_neighbors=29) 0.708 0.048\n",
      "KNeighborsClassifier(algorithm='kd_tree', n_neighbors=29) 0.708 0.048\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=40, n_neighbors=29) 0.708 0.048\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=50, n_neighbors=29) 0.708 0.048\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=60, n_neighbors=29) 0.708 0.048\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=70, n_neighbors=29) 0.708 0.048\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=80, n_neighbors=29) 0.708 0.048\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=10, n_neighbors=29) 0.707 0.047\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=20, n_neighbors=29) 0.707 0.047\n",
      "KNeighborsClassifier(algorithm='brute', n_neighbors=29) 0.707 0.047\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=40, n_neighbors=29) 0.707 0.047\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=50, n_neighbors=29) 0.707 0.047\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=60, n_neighbors=29) 0.707 0.047\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=70, n_neighbors=29) 0.707 0.047\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=80, n_neighbors=29) 0.707 0.047\n",
      "KNeighborsClassifier(leaf_size=10, n_neighbors=29, weights='distance') 0.718 0.046\n",
      "KNeighborsClassifier(leaf_size=20, n_neighbors=29, weights='distance') 0.718 0.046\n",
      "KNeighborsClassifier(n_neighbors=29, weights='distance') 0.718 0.046\n",
      "KNeighborsClassifier(leaf_size=40, n_neighbors=29, weights='distance') 0.718 0.046\n",
      "KNeighborsClassifier(leaf_size=50, n_neighbors=29, weights='distance') 0.718 0.046\n",
      "KNeighborsClassifier(leaf_size=60, n_neighbors=29, weights='distance') 0.718 0.046\n",
      "KNeighborsClassifier(leaf_size=70, n_neighbors=29, weights='distance') 0.718 0.046\n",
      "KNeighborsClassifier(leaf_size=80, n_neighbors=29, weights='distance') 0.718 0.046\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=10, n_neighbors=29,\n",
      "                     weights='distance') 0.719 0.047\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=20, n_neighbors=29,\n",
      "                     weights='distance') 0.719 0.047\n",
      "KNeighborsClassifier(algorithm='ball_tree', n_neighbors=29, weights='distance') 0.719 0.047\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=40, n_neighbors=29,\n",
      "                     weights='distance') 0.719 0.047\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=50, n_neighbors=29,\n",
      "                     weights='distance') 0.719 0.047\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=60, n_neighbors=29,\n",
      "                     weights='distance') 0.719 0.047\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=70, n_neighbors=29,\n",
      "                     weights='distance') 0.719 0.047\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=80, n_neighbors=29,\n",
      "                     weights='distance') 0.719 0.047\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=10, n_neighbors=29,\n",
      "                     weights='distance') 0.719 0.047\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=20, n_neighbors=29,\n",
      "                     weights='distance') 0.719 0.047\n",
      "KNeighborsClassifier(algorithm='kd_tree', n_neighbors=29, weights='distance') 0.719 0.047\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=40, n_neighbors=29,\n",
      "                     weights='distance') 0.719 0.047\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=50, n_neighbors=29,\n",
      "                     weights='distance') 0.719 0.047\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=60, n_neighbors=29,\n",
      "                     weights='distance') 0.719 0.047\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=70, n_neighbors=29,\n",
      "                     weights='distance') 0.719 0.047\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=80, n_neighbors=29,\n",
      "                     weights='distance') 0.719 0.047\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=10, n_neighbors=29,\n",
      "                     weights='distance') 0.718 0.046\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=20, n_neighbors=29,\n",
      "                     weights='distance') 0.718 0.046\n",
      "KNeighborsClassifier(algorithm='brute', n_neighbors=29, weights='distance') 0.718 0.046\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=40, n_neighbors=29,\n",
      "                     weights='distance') 0.718 0.046\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=50, n_neighbors=29,\n",
      "                     weights='distance') 0.718 0.046\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=60, n_neighbors=29,\n",
      "                     weights='distance') 0.718 0.046\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=70, n_neighbors=29,\n",
      "                     weights='distance') 0.718 0.046\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=80, n_neighbors=29,\n",
      "                     weights='distance') 0.718 0.046\n",
      "KNeighborsClassifier(leaf_size=10, n_neighbors=31) 0.708 0.049\n",
      "KNeighborsClassifier(leaf_size=20, n_neighbors=31) 0.708 0.049\n",
      "KNeighborsClassifier(n_neighbors=31) 0.708 0.049\n",
      "KNeighborsClassifier(leaf_size=40, n_neighbors=31) 0.708 0.049\n",
      "KNeighborsClassifier(leaf_size=50, n_neighbors=31) 0.708 0.049\n",
      "KNeighborsClassifier(leaf_size=60, n_neighbors=31) 0.708 0.049\n",
      "KNeighborsClassifier(leaf_size=70, n_neighbors=31) 0.708 0.049\n",
      "KNeighborsClassifier(leaf_size=80, n_neighbors=31) 0.708 0.049\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=10, n_neighbors=31) 0.707 0.051\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=20, n_neighbors=31) 0.707 0.051\n",
      "KNeighborsClassifier(algorithm='ball_tree', n_neighbors=31) 0.708 0.049\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=40, n_neighbors=31) 0.708 0.049\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=50, n_neighbors=31) 0.708 0.049\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=60, n_neighbors=31) 0.708 0.049\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=70, n_neighbors=31) 0.708 0.049\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=80, n_neighbors=31) 0.708 0.049\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=10, n_neighbors=31) 0.708 0.049\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=20, n_neighbors=31) 0.708 0.049\n",
      "KNeighborsClassifier(algorithm='kd_tree', n_neighbors=31) 0.707 0.051\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=40, n_neighbors=31) 0.707 0.051\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=50, n_neighbors=31) 0.707 0.051\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=60, n_neighbors=31) 0.707 0.051\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=70, n_neighbors=31) 0.707 0.051\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=80, n_neighbors=31) 0.707 0.051\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=10, n_neighbors=31) 0.708 0.049\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=20, n_neighbors=31) 0.708 0.049\n",
      "KNeighborsClassifier(algorithm='brute', n_neighbors=31) 0.708 0.049\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=40, n_neighbors=31) 0.708 0.049\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=50, n_neighbors=31) 0.708 0.049\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=60, n_neighbors=31) 0.708 0.049\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=70, n_neighbors=31) 0.708 0.049\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=80, n_neighbors=31) 0.708 0.049\n",
      "KNeighborsClassifier(leaf_size=10, n_neighbors=31, weights='distance') 0.711 0.049\n",
      "KNeighborsClassifier(leaf_size=20, n_neighbors=31, weights='distance') 0.711 0.049\n",
      "KNeighborsClassifier(n_neighbors=31, weights='distance') 0.711 0.049\n",
      "KNeighborsClassifier(leaf_size=40, n_neighbors=31, weights='distance') 0.711 0.049\n",
      "KNeighborsClassifier(leaf_size=50, n_neighbors=31, weights='distance') 0.711 0.049\n",
      "KNeighborsClassifier(leaf_size=60, n_neighbors=31, weights='distance') 0.711 0.049\n",
      "KNeighborsClassifier(leaf_size=70, n_neighbors=31, weights='distance') 0.711 0.049\n",
      "KNeighborsClassifier(leaf_size=80, n_neighbors=31, weights='distance') 0.711 0.049\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=10, n_neighbors=31,\n",
      "                     weights='distance') 0.71 0.051\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=20, n_neighbors=31,\n",
      "                     weights='distance') 0.71 0.051\n",
      "KNeighborsClassifier(algorithm='ball_tree', n_neighbors=31, weights='distance') 0.711 0.049\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=40, n_neighbors=31,\n",
      "                     weights='distance') 0.711 0.049\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=50, n_neighbors=31,\n",
      "                     weights='distance') 0.711 0.049\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=60, n_neighbors=31,\n",
      "                     weights='distance') 0.711 0.049\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=70, n_neighbors=31,\n",
      "                     weights='distance') 0.711 0.049\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=80, n_neighbors=31,\n",
      "                     weights='distance') 0.711 0.049\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=10, n_neighbors=31,\n",
      "                     weights='distance') 0.711 0.049\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=20, n_neighbors=31,\n",
      "                     weights='distance') 0.711 0.049\n",
      "KNeighborsClassifier(algorithm='kd_tree', n_neighbors=31, weights='distance') 0.71 0.051\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=40, n_neighbors=31,\n",
      "                     weights='distance') 0.71 0.051\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=50, n_neighbors=31,\n",
      "                     weights='distance') 0.71 0.051\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=60, n_neighbors=31,\n",
      "                     weights='distance') 0.71 0.051\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=70, n_neighbors=31,\n",
      "                     weights='distance') 0.71 0.051\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=80, n_neighbors=31,\n",
      "                     weights='distance') 0.71 0.051\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=10, n_neighbors=31,\n",
      "                     weights='distance') 0.711 0.049\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=20, n_neighbors=31,\n",
      "                     weights='distance') 0.711 0.049\n",
      "KNeighborsClassifier(algorithm='brute', n_neighbors=31, weights='distance') 0.711 0.049\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=40, n_neighbors=31,\n",
      "                     weights='distance') 0.711 0.049\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=50, n_neighbors=31,\n",
      "                     weights='distance') 0.711 0.049\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=60, n_neighbors=31,\n",
      "                     weights='distance') 0.711 0.049\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=70, n_neighbors=31,\n",
      "                     weights='distance') 0.711 0.049\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=80, n_neighbors=31,\n",
      "                     weights='distance') 0.711 0.049\n",
      "KNeighborsClassifier(leaf_size=10, n_neighbors=37) 0.717 0.067\n",
      "KNeighborsClassifier(leaf_size=20, n_neighbors=37) 0.717 0.067\n",
      "KNeighborsClassifier(n_neighbors=37) 0.717 0.067\n",
      "KNeighborsClassifier(leaf_size=40, n_neighbors=37) 0.717 0.067\n",
      "KNeighborsClassifier(leaf_size=50, n_neighbors=37) 0.717 0.067\n",
      "KNeighborsClassifier(leaf_size=60, n_neighbors=37) 0.717 0.067\n",
      "KNeighborsClassifier(leaf_size=70, n_neighbors=37) 0.717 0.067\n",
      "KNeighborsClassifier(leaf_size=80, n_neighbors=37) 0.717 0.067\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=10, n_neighbors=37) 0.717 0.067\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=20, n_neighbors=37) 0.717 0.067\n",
      "KNeighborsClassifier(algorithm='ball_tree', n_neighbors=37) 0.717 0.067\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=40, n_neighbors=37) 0.717 0.067\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=50, n_neighbors=37) 0.717 0.067\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=60, n_neighbors=37) 0.717 0.067\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=70, n_neighbors=37) 0.717 0.067\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=80, n_neighbors=37) 0.717 0.067\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=10, n_neighbors=37) 0.717 0.067\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=20, n_neighbors=37) 0.717 0.067\n",
      "KNeighborsClassifier(algorithm='kd_tree', n_neighbors=37) 0.717 0.067\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=40, n_neighbors=37) 0.717 0.067\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=50, n_neighbors=37) 0.717 0.067\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=60, n_neighbors=37) 0.717 0.067\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=70, n_neighbors=37) 0.717 0.067\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=80, n_neighbors=37) 0.717 0.067\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=10, n_neighbors=37) 0.717 0.067\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=20, n_neighbors=37) 0.717 0.067\n",
      "KNeighborsClassifier(algorithm='brute', n_neighbors=37) 0.717 0.067\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=40, n_neighbors=37) 0.717 0.067\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=50, n_neighbors=37) 0.717 0.067\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=60, n_neighbors=37) 0.717 0.067\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=70, n_neighbors=37) 0.717 0.067\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=80, n_neighbors=37) 0.717 0.067\n",
      "KNeighborsClassifier(leaf_size=10, n_neighbors=37, weights='distance') 0.73 0.063\n",
      "KNeighborsClassifier(leaf_size=20, n_neighbors=37, weights='distance') 0.73 0.063\n",
      "KNeighborsClassifier(n_neighbors=37, weights='distance') 0.73 0.063\n",
      "KNeighborsClassifier(leaf_size=40, n_neighbors=37, weights='distance') 0.73 0.063\n",
      "KNeighborsClassifier(leaf_size=50, n_neighbors=37, weights='distance') 0.73 0.063\n",
      "KNeighborsClassifier(leaf_size=60, n_neighbors=37, weights='distance') 0.73 0.063\n",
      "KNeighborsClassifier(leaf_size=70, n_neighbors=37, weights='distance') 0.73 0.063\n",
      "KNeighborsClassifier(leaf_size=80, n_neighbors=37, weights='distance') 0.73 0.063\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=10, n_neighbors=37,\n",
      "                     weights='distance') 0.73 0.063\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=20, n_neighbors=37,\n",
      "                     weights='distance') 0.73 0.063\n",
      "KNeighborsClassifier(algorithm='ball_tree', n_neighbors=37, weights='distance') 0.73 0.063\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=40, n_neighbors=37,\n",
      "                     weights='distance') 0.73 0.063\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=50, n_neighbors=37,\n",
      "                     weights='distance') 0.73 0.063\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=60, n_neighbors=37,\n",
      "                     weights='distance') 0.73 0.063\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=70, n_neighbors=37,\n",
      "                     weights='distance') 0.73 0.063\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=80, n_neighbors=37,\n",
      "                     weights='distance') 0.73 0.063\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=10, n_neighbors=37,\n",
      "                     weights='distance') 0.73 0.063\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=20, n_neighbors=37,\n",
      "                     weights='distance') 0.73 0.063\n",
      "KNeighborsClassifier(algorithm='kd_tree', n_neighbors=37, weights='distance') 0.73 0.063\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=40, n_neighbors=37,\n",
      "                     weights='distance') 0.73 0.063\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=50, n_neighbors=37,\n",
      "                     weights='distance') 0.73 0.063\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=60, n_neighbors=37,\n",
      "                     weights='distance') 0.73 0.063\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=70, n_neighbors=37,\n",
      "                     weights='distance') 0.73 0.063\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=80, n_neighbors=37,\n",
      "                     weights='distance') 0.73 0.063\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=10, n_neighbors=37,\n",
      "                     weights='distance') 0.73 0.063\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=20, n_neighbors=37,\n",
      "                     weights='distance') 0.73 0.063\n",
      "KNeighborsClassifier(algorithm='brute', n_neighbors=37, weights='distance') 0.73 0.063\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=40, n_neighbors=37,\n",
      "                     weights='distance') 0.73 0.063\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=50, n_neighbors=37,\n",
      "                     weights='distance') 0.73 0.063\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=60, n_neighbors=37,\n",
      "                     weights='distance') 0.73 0.063\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=70, n_neighbors=37,\n",
      "                     weights='distance') 0.73 0.063\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=80, n_neighbors=37,\n",
      "                     weights='distance') 0.73 0.063\n",
      "KNeighborsClassifier(leaf_size=10, n_neighbors=41) 0.718 0.065\n",
      "KNeighborsClassifier(leaf_size=20, n_neighbors=41) 0.718 0.065\n",
      "KNeighborsClassifier(n_neighbors=41) 0.718 0.065\n",
      "KNeighborsClassifier(leaf_size=40, n_neighbors=41) 0.718 0.065\n",
      "KNeighborsClassifier(leaf_size=50, n_neighbors=41) 0.718 0.065\n",
      "KNeighborsClassifier(leaf_size=60, n_neighbors=41) 0.718 0.065\n",
      "KNeighborsClassifier(leaf_size=70, n_neighbors=41) 0.718 0.065\n",
      "KNeighborsClassifier(leaf_size=80, n_neighbors=41) 0.718 0.065\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=10, n_neighbors=41) 0.718 0.065\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=20, n_neighbors=41) 0.718 0.065\n",
      "KNeighborsClassifier(algorithm='ball_tree', n_neighbors=41) 0.718 0.065\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=40, n_neighbors=41) 0.718 0.065\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=50, n_neighbors=41) 0.718 0.065\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=60, n_neighbors=41) 0.718 0.065\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=70, n_neighbors=41) 0.718 0.065\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=80, n_neighbors=41) 0.718 0.065\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=10, n_neighbors=41) 0.718 0.065\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=20, n_neighbors=41) 0.718 0.065\n",
      "KNeighborsClassifier(algorithm='kd_tree', n_neighbors=41) 0.718 0.065\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=40, n_neighbors=41) 0.718 0.065\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=50, n_neighbors=41) 0.718 0.065\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=60, n_neighbors=41) 0.718 0.065\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=70, n_neighbors=41) 0.718 0.065\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=80, n_neighbors=41) 0.718 0.065\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=10, n_neighbors=41) 0.718 0.065\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=20, n_neighbors=41) 0.718 0.065\n",
      "KNeighborsClassifier(algorithm='brute', n_neighbors=41) 0.718 0.065\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=40, n_neighbors=41) 0.718 0.065\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=50, n_neighbors=41) 0.718 0.065\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=60, n_neighbors=41) 0.718 0.065\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=70, n_neighbors=41) 0.718 0.065\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=80, n_neighbors=41) 0.718 0.065\n",
      "KNeighborsClassifier(leaf_size=10, n_neighbors=41, weights='distance') 0.733 0.057\n",
      "KNeighborsClassifier(leaf_size=20, n_neighbors=41, weights='distance') 0.733 0.057\n",
      "KNeighborsClassifier(n_neighbors=41, weights='distance') 0.733 0.057\n",
      "KNeighborsClassifier(leaf_size=40, n_neighbors=41, weights='distance') 0.733 0.057\n",
      "KNeighborsClassifier(leaf_size=50, n_neighbors=41, weights='distance') 0.733 0.057\n",
      "KNeighborsClassifier(leaf_size=60, n_neighbors=41, weights='distance') 0.733 0.057\n",
      "KNeighborsClassifier(leaf_size=70, n_neighbors=41, weights='distance') 0.733 0.057\n",
      "KNeighborsClassifier(leaf_size=80, n_neighbors=41, weights='distance') 0.733 0.057\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=10, n_neighbors=41,\n",
      "                     weights='distance') 0.733 0.057\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=20, n_neighbors=41,\n",
      "                     weights='distance') 0.733 0.057\n",
      "KNeighborsClassifier(algorithm='ball_tree', n_neighbors=41, weights='distance') 0.733 0.057\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=40, n_neighbors=41,\n",
      "                     weights='distance') 0.733 0.057\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=50, n_neighbors=41,\n",
      "                     weights='distance') 0.733 0.057\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=60, n_neighbors=41,\n",
      "                     weights='distance') 0.733 0.057\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=70, n_neighbors=41,\n",
      "                     weights='distance') 0.733 0.057\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=80, n_neighbors=41,\n",
      "                     weights='distance') 0.733 0.057\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=10, n_neighbors=41,\n",
      "                     weights='distance') 0.733 0.057\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=20, n_neighbors=41,\n",
      "                     weights='distance') 0.733 0.057\n",
      "KNeighborsClassifier(algorithm='kd_tree', n_neighbors=41, weights='distance') 0.733 0.057\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=40, n_neighbors=41,\n",
      "                     weights='distance') 0.733 0.057\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=50, n_neighbors=41,\n",
      "                     weights='distance') 0.733 0.057\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=60, n_neighbors=41,\n",
      "                     weights='distance') 0.733 0.057\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=70, n_neighbors=41,\n",
      "                     weights='distance') 0.733 0.057\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=80, n_neighbors=41,\n",
      "                     weights='distance') 0.733 0.057\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=10, n_neighbors=41,\n",
      "                     weights='distance') 0.733 0.057\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=20, n_neighbors=41,\n",
      "                     weights='distance') 0.733 0.057\n",
      "KNeighborsClassifier(algorithm='brute', n_neighbors=41, weights='distance') 0.733 0.057\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=40, n_neighbors=41,\n",
      "                     weights='distance') 0.733 0.057\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=50, n_neighbors=41,\n",
      "                     weights='distance') 0.733 0.057\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=60, n_neighbors=41,\n",
      "                     weights='distance') 0.733 0.057\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=70, n_neighbors=41,\n",
      "                     weights='distance') 0.733 0.057\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=80, n_neighbors=41,\n",
      "                     weights='distance') 0.733 0.057\n",
      "KNeighborsClassifier(leaf_size=10, n_neighbors=43) 0.71 0.055\n",
      "KNeighborsClassifier(leaf_size=20, n_neighbors=43) 0.71 0.055\n",
      "KNeighborsClassifier(n_neighbors=43) 0.71 0.055\n",
      "KNeighborsClassifier(leaf_size=40, n_neighbors=43) 0.71 0.055\n",
      "KNeighborsClassifier(leaf_size=50, n_neighbors=43) 0.71 0.055\n",
      "KNeighborsClassifier(leaf_size=60, n_neighbors=43) 0.71 0.055\n",
      "KNeighborsClassifier(leaf_size=70, n_neighbors=43) 0.71 0.055\n",
      "KNeighborsClassifier(leaf_size=80, n_neighbors=43) 0.71 0.055\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=10, n_neighbors=43) 0.71 0.055\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=20, n_neighbors=43) 0.71 0.055\n",
      "KNeighborsClassifier(algorithm='ball_tree', n_neighbors=43) 0.709 0.055\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=40, n_neighbors=43) 0.709 0.055\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=50, n_neighbors=43) 0.709 0.055\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=60, n_neighbors=43) 0.709 0.055\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=70, n_neighbors=43) 0.709 0.055\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=80, n_neighbors=43) 0.709 0.055\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=10, n_neighbors=43) 0.71 0.055\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=20, n_neighbors=43) 0.71 0.055\n",
      "KNeighborsClassifier(algorithm='kd_tree', n_neighbors=43) 0.71 0.055\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=40, n_neighbors=43) 0.71 0.055\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=50, n_neighbors=43) 0.71 0.055\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=60, n_neighbors=43) 0.71 0.055\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=70, n_neighbors=43) 0.71 0.055\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=80, n_neighbors=43) 0.71 0.055\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=10, n_neighbors=43) 0.71 0.055\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=20, n_neighbors=43) 0.71 0.055\n",
      "KNeighborsClassifier(algorithm='brute', n_neighbors=43) 0.71 0.055\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=40, n_neighbors=43) 0.71 0.055\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=50, n_neighbors=43) 0.71 0.055\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=60, n_neighbors=43) 0.71 0.055\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=70, n_neighbors=43) 0.71 0.055\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=80, n_neighbors=43) 0.71 0.055\n",
      "KNeighborsClassifier(leaf_size=10, n_neighbors=43, weights='distance') 0.73 0.055\n",
      "KNeighborsClassifier(leaf_size=20, n_neighbors=43, weights='distance') 0.73 0.055\n",
      "KNeighborsClassifier(n_neighbors=43, weights='distance') 0.73 0.055\n",
      "KNeighborsClassifier(leaf_size=40, n_neighbors=43, weights='distance') 0.73 0.055\n",
      "KNeighborsClassifier(leaf_size=50, n_neighbors=43, weights='distance') 0.73 0.055\n",
      "KNeighborsClassifier(leaf_size=60, n_neighbors=43, weights='distance') 0.73 0.055\n",
      "KNeighborsClassifier(leaf_size=70, n_neighbors=43, weights='distance') 0.73 0.055\n",
      "KNeighborsClassifier(leaf_size=80, n_neighbors=43, weights='distance') 0.73 0.055\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=10, n_neighbors=43,\n",
      "                     weights='distance') 0.73 0.055\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=20, n_neighbors=43,\n",
      "                     weights='distance') 0.73 0.055\n",
      "KNeighborsClassifier(algorithm='ball_tree', n_neighbors=43, weights='distance') 0.729 0.056\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=40, n_neighbors=43,\n",
      "                     weights='distance') 0.729 0.056\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=50, n_neighbors=43,\n",
      "                     weights='distance') 0.729 0.056\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=60, n_neighbors=43,\n",
      "                     weights='distance') 0.729 0.056\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=70, n_neighbors=43,\n",
      "                     weights='distance') 0.729 0.056\n",
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=80, n_neighbors=43,\n",
      "                     weights='distance') 0.729 0.056\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=10, n_neighbors=43,\n",
      "                     weights='distance') 0.73 0.055\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=20, n_neighbors=43,\n",
      "                     weights='distance') 0.73 0.055\n",
      "KNeighborsClassifier(algorithm='kd_tree', n_neighbors=43, weights='distance') 0.73 0.055\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=40, n_neighbors=43,\n",
      "                     weights='distance') 0.73 0.055\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=50, n_neighbors=43,\n",
      "                     weights='distance') 0.73 0.055\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=60, n_neighbors=43,\n",
      "                     weights='distance') 0.73 0.055\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=70, n_neighbors=43,\n",
      "                     weights='distance') 0.73 0.055\n",
      "KNeighborsClassifier(algorithm='kd_tree', leaf_size=80, n_neighbors=43,\n",
      "                     weights='distance') 0.73 0.055\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=10, n_neighbors=43,\n",
      "                     weights='distance') 0.73 0.055\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=20, n_neighbors=43,\n",
      "                     weights='distance') 0.73 0.055\n",
      "KNeighborsClassifier(algorithm='brute', n_neighbors=43, weights='distance') 0.73 0.055\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=40, n_neighbors=43,\n",
      "                     weights='distance') 0.73 0.055\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=50, n_neighbors=43,\n",
      "                     weights='distance') 0.73 0.055\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=60, n_neighbors=43,\n",
      "                     weights='distance') 0.73 0.055\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=70, n_neighbors=43,\n",
      "                     weights='distance') 0.73 0.055\n",
      "KNeighborsClassifier(algorithm='brute', leaf_size=80, n_neighbors=43,\n",
      "                     weights='distance') 0.73 0.055\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc_cv_mean_collection = []\n",
    "n_neighbors = [2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43]\n",
    "weights = ['uniform', 'distance']\n",
    "algorithm = ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "leaf_size = [10, 20, 30, 40, 50, 60, 70, 80]\n",
    "for i in n_neighbors:\n",
    "    for j in weights:\n",
    "        for k in algorithm:\n",
    "            for p in leaf_size:\n",
    "                acc_cv_collection = []\n",
    "                clf = KNeighborsClassifier(n_neighbors=i, weights=j, algorithm=k,\n",
    "                                           leaf_size=p)  # need to tune the hyperparameters\n",
    "                from sklearn.model_selection import cross_val_score, KFold, StratifiedKFold\n",
    "                skf = StratifiedKFold(n_splits=10)\n",
    "                for train, test in skf.split(X_train_whole, y_train_whole):\n",
    "                    X_train, X_valid, y_train, y_valid = np.take(X_train_whole, train.tolist(), axis=0), np.take(X_train_whole,\n",
    "                                                                                                                test.tolist(),\n",
    "                                                                                                                axis=0), np.take(\n",
    "                        y_train_whole, train.tolist(), axis=0), np.take(y_train_whole, test.tolist(), axis=0)\n",
    "                    clf.fit(X_train, y_train)\n",
    "                    y_valid_pred = clf.predict(X_valid)\n",
    "                    acc_cv = balanced_accuracy_score(y_valid, y_valid_pred)\n",
    "                    # print(acc_cv)\n",
    "                    acc_cv_collection.append(acc_cv)\n",
    "                acc_cv_mean_collection.append(round(statistics.mean(acc_cv_collection),3))\n",
    "                print(clf,round(statistics.mean(acc_cv_collection),3), round(statistics.stdev(acc_cv_collection),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qoJpjw-uCihR",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CUUyFzZiGq0j",
    "outputId": "acd0b4ed-71e4-40f6-e2da-d50ebba311af",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC(C=0.0001, max_iter=80000, tol=1e-05) 0.753 0.044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC(C=0.01, max_iter=80000, tol=1e-05) 0.743 0.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC(C=0.1, max_iter=80000, tol=1e-05) 0.738 0.057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC(C=0.5, max_iter=80000, tol=1e-05) 0.729 0.049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC(C=1.1, max_iter=80000, tol=1e-05) 0.717 0.048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[14], line 22\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m train, test \u001B[38;5;129;01min\u001B[39;00m skf\u001B[38;5;241m.\u001B[39msplit(X_train_whole, y_train_whole):\n\u001B[1;32m     18\u001B[0m     X_train, X_valid, y_train, y_valid \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mtake(X_train_whole, train\u001B[38;5;241m.\u001B[39mtolist(), axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m), np\u001B[38;5;241m.\u001B[39mtake(X_train_whole,\n\u001B[1;32m     19\u001B[0m                                                                                                 test\u001B[38;5;241m.\u001B[39mtolist(),\n\u001B[1;32m     20\u001B[0m                                                                                                 axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m), np\u001B[38;5;241m.\u001B[39mtake(\n\u001B[1;32m     21\u001B[0m         y_train_whole, train\u001B[38;5;241m.\u001B[39mtolist(), axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m), np\u001B[38;5;241m.\u001B[39mtake(y_train_whole, test\u001B[38;5;241m.\u001B[39mtolist(), axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m---> 22\u001B[0m     \u001B[43mclf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     23\u001B[0m     y_valid_pred \u001B[38;5;241m=\u001B[39m clf\u001B[38;5;241m.\u001B[39mpredict(X_valid)\n\u001B[1;32m     24\u001B[0m     acc_cv \u001B[38;5;241m=\u001B[39m balanced_accuracy_score(y_valid, y_valid_pred)\n",
      "File \u001B[0;32m~/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/svm/_classes.py:274\u001B[0m, in \u001B[0;36mLinearSVC.fit\u001B[0;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[1;32m    271\u001B[0m check_classification_targets(y)\n\u001B[1;32m    272\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclasses_ \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39munique(y)\n\u001B[0;32m--> 274\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcoef_, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mintercept_, n_iter_ \u001B[38;5;241m=\u001B[39m \u001B[43m_fit_liblinear\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    275\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    276\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    277\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mC\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    278\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_intercept\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    279\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mintercept_scaling\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    280\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclass_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    281\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpenalty\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    282\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdual\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    283\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    284\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_iter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    285\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtol\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    286\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrandom_state\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    287\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmulti_class\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    288\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloss\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    289\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    290\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    291\u001B[0m \u001B[38;5;66;03m# Backward compatibility: _fit_liblinear is used both by LinearSVC/R\u001B[39;00m\n\u001B[1;32m    292\u001B[0m \u001B[38;5;66;03m# and LogisticRegression but LogisticRegression sets a structured\u001B[39;00m\n\u001B[1;32m    293\u001B[0m \u001B[38;5;66;03m# `n_iter_` attribute with information about the underlying OvR fits\u001B[39;00m\n\u001B[1;32m    294\u001B[0m \u001B[38;5;66;03m# while LinearSVC/R only reports the maximum value.\u001B[39;00m\n\u001B[1;32m    295\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_iter_ \u001B[38;5;241m=\u001B[39m n_iter_\u001B[38;5;241m.\u001B[39mmax()\u001B[38;5;241m.\u001B[39mitem()\n",
      "File \u001B[0;32m~/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/svm/_base.py:1224\u001B[0m, in \u001B[0;36m_fit_liblinear\u001B[0;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001B[0m\n\u001B[1;32m   1221\u001B[0m sample_weight \u001B[38;5;241m=\u001B[39m _check_sample_weight(sample_weight, X, dtype\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mfloat64)\n\u001B[1;32m   1223\u001B[0m solver_type \u001B[38;5;241m=\u001B[39m _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n\u001B[0;32m-> 1224\u001B[0m raw_coef_, n_iter_ \u001B[38;5;241m=\u001B[39m \u001B[43mliblinear\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_wrap\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1225\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1226\u001B[0m \u001B[43m    \u001B[49m\u001B[43my_ind\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1227\u001B[0m \u001B[43m    \u001B[49m\u001B[43msp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43misspmatrix\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1228\u001B[0m \u001B[43m    \u001B[49m\u001B[43msolver_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1229\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtol\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1230\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1231\u001B[0m \u001B[43m    \u001B[49m\u001B[43mC\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1232\u001B[0m \u001B[43m    \u001B[49m\u001B[43mclass_weight_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1233\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_iter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1234\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrnd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrandint\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miinfo\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mi\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1235\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepsilon\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1236\u001B[0m \u001B[43m    \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1237\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1238\u001B[0m \u001B[38;5;66;03m# Regarding rnd.randint(..) in the above signature:\u001B[39;00m\n\u001B[1;32m   1239\u001B[0m \u001B[38;5;66;03m# seed for srand in range [0..INT_MAX); due to limitations in Numpy\u001B[39;00m\n\u001B[1;32m   1240\u001B[0m \u001B[38;5;66;03m# on 32-bit platforms, we can't get to the UINT_MAX limit that\u001B[39;00m\n\u001B[1;32m   1241\u001B[0m \u001B[38;5;66;03m# srand supports\u001B[39;00m\n\u001B[1;32m   1242\u001B[0m n_iter_max \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmax\u001B[39m(n_iter_)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# LinearSVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc_cv_mean_collection = []\n",
    "C = [0.0001, 0.01, 0.1,  0.5, 1.1, 1.3, 10,20, 30, 40, 50,60, 70, 80, 90, 100, 300]\n",
    "degree = [1]\n",
    "tol = [1e-5]\n",
    "for i in C:\n",
    "    for k in degree:\n",
    "        for p in tol:\n",
    "            acc_cv_collection = []\n",
    "            clf = LinearSVC(C=i, tol=p, max_iter= 80000)  # need to tune the hyperparameters\n",
    "            from sklearn.model_selection import cross_val_score, KFold, StratifiedKFold\n",
    "            skf = StratifiedKFold(n_splits=10)\n",
    "            for train, test in skf.split(X_train_whole, y_train_whole):\n",
    "                X_train, X_valid, y_train, y_valid = np.take(X_train_whole, train.tolist(), axis=0), np.take(X_train_whole,\n",
    "                                                                                                            test.tolist(),\n",
    "                                                                                                            axis=0), np.take(\n",
    "                    y_train_whole, train.tolist(), axis=0), np.take(y_train_whole, test.tolist(), axis=0)\n",
    "                clf.fit(X_train, y_train)\n",
    "                y_valid_pred = clf.predict(X_valid)\n",
    "                acc_cv = balanced_accuracy_score(y_valid, y_valid_pred)\n",
    "                acc_cv_collection.append(acc_cv)\n",
    "            acc_cv_mean_collection.append(round(statistics.mean(acc_cv_collection),3))\n",
    "            print(clf,round(statistics.mean(acc_cv_collection),3), round(statistics.stdev(acc_cv_collection),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2V4Lif5bG0tU",
    "outputId": "dbf1a96e-67a5-48e2-ee6b-038289f7b682",
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=0.001, degree=1, kernel='linear') 0.748 0.041\n",
      "SVC(C=0.001, kernel='linear') 0.748 0.041\n",
      "SVC(C=0.001, degree=5, kernel='linear') 0.748 0.041\n",
      "SVC(C=0.001, degree=7, kernel='linear') 0.748 0.041\n",
      "SVC(C=0.001, degree=9, kernel='linear') 0.748 0.041\n",
      "SVC(C=0.001, degree=1, kernel='poly') 0.5 0.0\n",
      "SVC(C=0.001, kernel='poly') 0.5 0.0\n",
      "SVC(C=0.001, degree=5, kernel='poly') 0.519 0.016\n",
      "SVC(C=0.001, degree=7, kernel='poly') 0.696 0.041\n",
      "SVC(C=0.001, degree=9, kernel='poly') 0.745 0.044\n",
      "SVC(C=0.001, degree=1) 0.5 0.0\n",
      "SVC(C=0.001) 0.5 0.0\n",
      "SVC(C=0.001, degree=5) 0.5 0.0\n",
      "SVC(C=0.001, degree=7) 0.5 0.0\n",
      "SVC(C=0.001, degree=9) 0.5 0.0\n",
      "SVC(C=0.001, degree=1, kernel='sigmoid') 0.5 0.0\n",
      "SVC(C=0.001, kernel='sigmoid') 0.5 0.0\n",
      "SVC(C=0.001, degree=5, kernel='sigmoid') 0.5 0.0\n",
      "SVC(C=0.001, degree=7, kernel='sigmoid') 0.5 0.0\n",
      "SVC(C=0.001, degree=9, kernel='sigmoid') 0.5 0.0\n",
      "SVC(C=0.01, degree=1, kernel='linear') 0.745 0.036\n",
      "SVC(C=0.01, kernel='linear') 0.745 0.036\n",
      "SVC(C=0.01, degree=5, kernel='linear') 0.745 0.036\n",
      "SVC(C=0.01, degree=7, kernel='linear') 0.745 0.036\n",
      "SVC(C=0.01, degree=9, kernel='linear') 0.745 0.036\n",
      "SVC(C=0.01, degree=1, kernel='poly') 0.5 0.0\n",
      "SVC(C=0.01, kernel='poly') 0.57 0.034\n",
      "SVC(C=0.01, degree=5, kernel='poly') 0.731 0.048\n",
      "SVC(C=0.01, degree=7, kernel='poly') 0.752 0.038\n",
      "SVC(C=0.01, degree=9, kernel='poly') 0.736 0.05\n",
      "SVC(C=0.01, degree=1) 0.5 0.0\n",
      "SVC(C=0.01) 0.5 0.0\n",
      "SVC(C=0.01, degree=5) 0.5 0.0\n",
      "SVC(C=0.01, degree=7) 0.5 0.0\n",
      "SVC(C=0.01, degree=9) 0.5 0.0\n",
      "SVC(C=0.01, degree=1, kernel='sigmoid') 0.5 0.0\n",
      "SVC(C=0.01, kernel='sigmoid') 0.5 0.0\n",
      "SVC(C=0.01, degree=5, kernel='sigmoid') 0.5 0.0\n",
      "SVC(C=0.01, degree=7, kernel='sigmoid') 0.5 0.0\n",
      "SVC(C=0.01, degree=9, kernel='sigmoid') 0.5 0.0\n",
      "SVC(C=0.1, degree=1, kernel='linear') 0.754 0.039\n",
      "SVC(C=0.1, kernel='linear') 0.754 0.039\n",
      "SVC(C=0.1, degree=5, kernel='linear') 0.754 0.039\n",
      "SVC(C=0.1, degree=7, kernel='linear') 0.754 0.039\n",
      "SVC(C=0.1, degree=9, kernel='linear') 0.754 0.039\n",
      "SVC(C=0.1, degree=1, kernel='poly') 0.574 0.023\n",
      "SVC(C=0.1, kernel='poly') 0.735 0.057\n",
      "SVC(C=0.1, degree=5, kernel='poly') 0.771 0.042\n",
      "SVC(C=0.1, degree=7, kernel='poly') 0.744 0.058\n",
      "SVC(C=0.1, degree=9, kernel='poly') 0.73 0.063\n",
      "SVC(C=0.1, degree=1) 0.523 0.02\n",
      "SVC(C=0.1) 0.523 0.02\n",
      "SVC(C=0.1, degree=5) 0.523 0.02\n",
      "SVC(C=0.1, degree=7) 0.523 0.02\n",
      "SVC(C=0.1, degree=9) 0.523 0.02\n",
      "SVC(C=0.1, degree=1, kernel='sigmoid') 0.502 0.005\n",
      "SVC(C=0.1, kernel='sigmoid') 0.502 0.005\n",
      "SVC(C=0.1, degree=5, kernel='sigmoid') 0.502 0.005\n",
      "SVC(C=0.1, degree=7, kernel='sigmoid') 0.502 0.005\n",
      "SVC(C=0.1, degree=9, kernel='sigmoid') 0.502 0.005\n",
      "SVC(C=0.5, degree=1, kernel='linear') 0.744 0.045\n",
      "SVC(C=0.5, kernel='linear') 0.744 0.045\n",
      "SVC(C=0.5, degree=5, kernel='linear') 0.744 0.045\n",
      "SVC(C=0.5, degree=7, kernel='linear') 0.744 0.045\n",
      "SVC(C=0.5, degree=9, kernel='linear') 0.744 0.045\n",
      "SVC(C=0.5, degree=1, kernel='poly') 0.704 0.047\n",
      "SVC(C=0.5, kernel='poly') 0.775 0.048\n",
      "SVC(C=0.5, degree=5, kernel='poly') 0.763 0.049\n",
      "SVC(C=0.5, degree=7, kernel='poly') 0.734 0.069\n",
      "SVC(C=0.5, degree=9, kernel='poly') 0.73 0.068\n",
      "SVC(C=0.5, degree=1) 0.71 0.05\n",
      "SVC(C=0.5) 0.71 0.05\n",
      "SVC(C=0.5, degree=5) 0.71 0.05\n",
      "SVC(C=0.5, degree=7) 0.71 0.05\n",
      "SVC(C=0.5, degree=9) 0.71 0.05\n",
      "SVC(C=0.5, degree=1, kernel='sigmoid') 0.508 0.034\n",
      "SVC(C=0.5, kernel='sigmoid') 0.508 0.034\n",
      "SVC(C=0.5, degree=5, kernel='sigmoid') 0.508 0.034\n",
      "SVC(C=0.5, degree=7, kernel='sigmoid') 0.508 0.034\n",
      "SVC(C=0.5, degree=9, kernel='sigmoid') 0.508 0.034\n",
      "SVC(C=1.1, degree=1, kernel='linear') 0.739 0.04\n",
      "SVC(C=1.1, kernel='linear') 0.739 0.04\n",
      "SVC(C=1.1, degree=5, kernel='linear') 0.739 0.04\n",
      "SVC(C=1.1, degree=7, kernel='linear') 0.739 0.04\n",
      "SVC(C=1.1, degree=9, kernel='linear') 0.739 0.04\n",
      "SVC(C=1.1, degree=1, kernel='poly') 0.736 0.047\n",
      "SVC(C=1.1, kernel='poly') 0.784 0.054\n",
      "SVC(C=1.1, degree=5, kernel='poly') 0.752 0.051\n",
      "SVC(C=1.1, degree=7, kernel='poly') 0.737 0.068\n",
      "SVC(C=1.1, degree=9, kernel='poly') 0.73 0.068\n",
      "SVC(C=1.1, degree=1) 0.755 0.049\n",
      "SVC(C=1.1) 0.755 0.049\n",
      "SVC(C=1.1, degree=5) 0.755 0.049\n",
      "SVC(C=1.1, degree=7) 0.755 0.049\n",
      "SVC(C=1.1, degree=9) 0.755 0.049\n",
      "SVC(C=1.1, degree=1, kernel='sigmoid') 0.551 0.054\n",
      "SVC(C=1.1, kernel='sigmoid') 0.551 0.054\n",
      "SVC(C=1.1, degree=5, kernel='sigmoid') 0.551 0.054\n",
      "SVC(C=1.1, degree=7, kernel='sigmoid') 0.551 0.054\n",
      "SVC(C=1.1, degree=9, kernel='sigmoid') 0.551 0.054\n",
      "SVC(C=1.3, degree=1, kernel='linear') 0.74 0.041\n",
      "SVC(C=1.3, kernel='linear') 0.74 0.041\n",
      "SVC(C=1.3, degree=5, kernel='linear') 0.74 0.041\n",
      "SVC(C=1.3, degree=7, kernel='linear') 0.74 0.041\n",
      "SVC(C=1.3, degree=9, kernel='linear') 0.74 0.041\n",
      "SVC(C=1.3, degree=1, kernel='poly') 0.744 0.054\n",
      "SVC(C=1.3, kernel='poly') 0.775 0.046\n",
      "SVC(C=1.3, degree=5, kernel='poly') 0.751 0.053\n",
      "SVC(C=1.3, degree=7, kernel='poly') 0.737 0.068\n",
      "SVC(C=1.3, degree=9, kernel='poly') 0.73 0.068\n",
      "SVC(C=1.3, degree=1) 0.768 0.048\n",
      "SVC(C=1.3) 0.768 0.048\n",
      "SVC(C=1.3, degree=5) 0.768 0.048\n",
      "SVC(C=1.3, degree=7) 0.768 0.048\n",
      "SVC(C=1.3, degree=9) 0.768 0.048\n",
      "SVC(C=1.3, degree=1, kernel='sigmoid') 0.585 0.044\n",
      "SVC(C=1.3, kernel='sigmoid') 0.585 0.044\n",
      "SVC(C=1.3, degree=5, kernel='sigmoid') 0.585 0.044\n",
      "SVC(C=1.3, degree=7, kernel='sigmoid') 0.585 0.044\n",
      "SVC(C=1.3, degree=9, kernel='sigmoid') 0.585 0.044\n",
      "SVC(C=5, degree=1, kernel='linear') 0.738 0.043\n",
      "SVC(C=5, kernel='linear') 0.738 0.043\n",
      "SVC(C=5, degree=5, kernel='linear') 0.737 0.047\n",
      "SVC(C=5, degree=7, kernel='linear') 0.736 0.043\n",
      "SVC(C=5, degree=9, kernel='linear') 0.738 0.043\n",
      "SVC(C=5, degree=1, kernel='poly') 0.769 0.048\n",
      "SVC(C=5, kernel='poly') 0.777 0.051\n",
      "SVC(C=5, degree=5, kernel='poly') 0.752 0.058\n",
      "SVC(C=5, degree=7, kernel='poly') 0.737 0.068\n",
      "SVC(C=5, degree=9, kernel='poly') 0.73 0.068\n",
      "SVC(C=5, degree=1) 0.783 0.046\n",
      "SVC(C=5) 0.783 0.046\n",
      "SVC(C=5, degree=5) 0.783 0.046\n",
      "SVC(C=5, degree=7) 0.783 0.046\n",
      "SVC(C=5, degree=9) 0.783 0.046\n",
      "SVC(C=5, degree=1, kernel='sigmoid') 0.58 0.056\n",
      "SVC(C=5, kernel='sigmoid') 0.58 0.056\n",
      "SVC(C=5, degree=5, kernel='sigmoid') 0.58 0.056\n",
      "SVC(C=5, degree=7, kernel='sigmoid') 0.58 0.056\n",
      "SVC(C=5, degree=9, kernel='sigmoid') 0.58 0.056\n",
      "SVC(C=10, degree=1, kernel='linear') 0.733 0.046\n",
      "SVC(C=10, kernel='linear') 0.733 0.046\n",
      "SVC(C=10, degree=5, kernel='linear') 0.733 0.046\n",
      "SVC(C=10, degree=7, kernel='linear') 0.734 0.045\n",
      "SVC(C=10, degree=9, kernel='linear') 0.741 0.036\n",
      "SVC(C=10, degree=1, kernel='poly') 0.761 0.052\n",
      "SVC(C=10, kernel='poly') 0.771 0.057\n",
      "SVC(C=10, degree=5, kernel='poly') 0.752 0.058\n",
      "SVC(C=10, degree=7, kernel='poly') 0.737 0.068\n",
      "SVC(C=10, degree=9, kernel='poly') 0.73 0.068\n",
      "SVC(C=10, degree=1) 0.776 0.043\n",
      "SVC(C=10) 0.776 0.043\n",
      "SVC(C=10, degree=5) 0.776 0.043\n",
      "SVC(C=10, degree=7) 0.776 0.043\n",
      "SVC(C=10, degree=9) 0.776 0.043\n",
      "SVC(C=10, degree=1, kernel='sigmoid') 0.586 0.048\n",
      "SVC(C=10, kernel='sigmoid') 0.586 0.048\n",
      "SVC(C=10, degree=5, kernel='sigmoid') 0.586 0.048\n",
      "SVC(C=10, degree=7, kernel='sigmoid') 0.586 0.048\n",
      "SVC(C=10, degree=9, kernel='sigmoid') 0.586 0.048\n",
      "SVC(C=30, degree=1, kernel='linear') 0.745 0.043\n",
      "SVC(C=30, kernel='linear') 0.75 0.041\n",
      "SVC(C=30, degree=5, kernel='linear') 0.742 0.042\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc_cv_mean_collection = []\n",
    "C = [0.001, 0.01, 0.1,  0.5, 1.1, 1.3, 5, 10, 30, 50, 100, 300]\n",
    "kernel = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "degree = [1, 3, 5, 7, 9]\n",
    "tol = [1e-5]\n",
    "for i in C:\n",
    "    for j in kernel:\n",
    "        for k in degree:\n",
    "            for p in tol:\n",
    "                acc_cv_collection = []\n",
    "                clf = SVC(C=i, kernel=j, degree=k)  # need to tune the hyperparameters\n",
    "                from sklearn.model_selection import cross_val_score, KFold, StratifiedKFold\n",
    "                skf = StratifiedKFold(n_splits=10)\n",
    "                for train, test in skf.split(X_train_whole, y_train_whole):\n",
    "                    X_train, X_valid, y_train, y_valid = np.take(X_train_whole, train.tolist(), axis=0), np.take(X_train_whole,\n",
    "                                                                                                                test.tolist(),\n",
    "                                                                                                                axis=0), np.take(\n",
    "                        y_train_whole, train.tolist(), axis=0), np.take(y_train_whole, test.tolist(), axis=0)\n",
    "                    clf.fit(X_train, y_train)\n",
    "                    y_valid_pred = clf.predict(X_valid)\n",
    "                    acc_cv = balanced_accuracy_score(y_valid, y_valid_pred)\n",
    "                    acc_cv_collection.append(acc_cv)\n",
    "                acc_cv_mean_collection.append(round(statistics.mean(acc_cv_collection),3))\n",
    "                print(clf,round(statistics.mean(acc_cv_collection),3), round(statistics.stdev(acc_cv_collection),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XUm2yu6cCqi7",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KBZ7o-bEb38a",
    "outputId": "ecfbd50d-4209-4580-fe8f-061d3f412b0c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(1,), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.504 0.021\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(2,), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.542 0.09\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(3,), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.543 0.083\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(4,), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.558 0.083\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(6,), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.55 0.047\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(8,), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.599 0.077\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(12,), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.626 0.112\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(16,), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.645 0.092\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(18,), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.659 0.097\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(20,), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.671 0.063\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(22,), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.677 0.059\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(24,), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.682 0.052\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(26,), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.68 0.037\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(28,), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.656 0.091\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(32,), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.695 0.051\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(64,), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.665 0.074\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(128,), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.66 0.066\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(240,), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.708 0.058\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(320,), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.718 0.046\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(640,), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.747 0.042\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(1280,), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.73 0.056\n"
     ]
    }
   ],
   "source": [
    "# MLP one layer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "hidden_layers_1 = [1,2,3,4,6,8,12,16, 18, 20, 22, 24,26,28,32, 64, 128, 240, 320, 640,1280]\n",
    "\n",
    "acc_cv_mean_collection = []\n",
    "for i in hidden_layers_1:\n",
    "    acc_cv_collection = []\n",
    "    clf = MLPClassifier(hidden_layer_sizes=(i,),early_stopping= True,n_iter_no_change= 40, max_iter = 3000)  # need to tune the hyperparameters\n",
    "    from sklearn.model_selection import cross_val_score, KFold, StratifiedKFold\n",
    "    skf = StratifiedKFold(n_splits=10)\n",
    "    for train, test in skf.split(X_train_whole, y_train_whole):\n",
    "        X_train, X_valid, y_train, y_valid = np.take(X_train_whole, train.tolist(), axis=0), np.take(X_train_whole,\n",
    "                                                                                                     test.tolist(),\n",
    "                                                                                                     axis=0), np.take(\n",
    "            y_train_whole, train.tolist(), axis=0), np.take(y_train_whole, test.tolist(), axis=0)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_valid_pred = clf.predict(X_valid)\n",
    "        y_train_pred = clf.predict(X_train)\n",
    "        # print(balanced_accuracy_score(y_train, y_train_pred))\n",
    "        acc_cv = balanced_accuracy_score(y_valid, y_valid_pred)\n",
    "        acc_cv_collection.append(acc_cv)\n",
    "    acc_cv_mean_collection.append(round(statistics.mean(acc_cv_collection),3))\n",
    "    print(clf,round(statistics.mean(acc_cv_collection),3),  round(statistics.stdev(acc_cv_collection),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Ke2HDzyFciIi",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "b4c9229e-d47b-4dc8-8843-a3e73c8b8de6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(12, 2), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.523 0.071\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(12, 8), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.579 0.095\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(12, 12), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.605 0.061\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(12, 24), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.567 0.077\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(12, 32), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.614 0.069\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(12, 64), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.626 0.054\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(12, 128), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.631 0.054\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(12, 256), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.609 0.081\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(24, 2), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.54 0.064\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(24, 8), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.611 0.09\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(24, 12), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.611 0.086\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(24, 24), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.623 0.045\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(24, 32), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.632 0.078\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(24, 64), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.671 0.055\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(24, 128), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.677 0.049\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(24, 256), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.664 0.059\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(32, 2), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.498 0.005\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(32, 8), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.598 0.081\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(32, 12), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.655 0.084\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(32, 24), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.694 0.029\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(32, 32), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.67 0.039\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(32, 64), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.673 0.058\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(32, 128), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.692 0.064\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(32, 256), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.665 0.069\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(64, 2), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.57 0.125\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(64, 8), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.624 0.114\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(64, 12), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.689 0.077\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(64, 24), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.684 0.056\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(64, 32), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.662 0.075\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(64, 64), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.642 0.069\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(64, 128), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.688 0.042\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(64, 256), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.694 0.072\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(128, 2), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.503 0.008\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(128, 8), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.59 0.101\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(128, 12), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.667 0.08\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(128, 24), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.711 0.076\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(128, 32), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.679 0.051\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(128, 64), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.681 0.056\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(128, 128), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.664 0.057\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(128, 256), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.701 0.032\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(256, 2), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.538 0.095\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(256, 8), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.649 0.128\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(256, 12), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.676 0.095\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(256, 24), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.723 0.051\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(256, 32), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.735 0.046\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(256, 64), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.709 0.06\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(256, 128), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.73 0.052\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(256, 256), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.729 0.041\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(320, 2), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.502 0.006\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(320, 8), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.62 0.13\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(320, 12), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.644 0.1\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(320, 24), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.74 0.041\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(320, 32), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.711 0.061\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(320, 64), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.692 0.041\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(320, 128), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.701 0.055\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(320, 256), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.742 0.049\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(640, 2), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.578 0.126\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(640, 8), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.598 0.127\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(640, 12), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.617 0.117\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(640, 24), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.748 0.042\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(640, 32), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.756 0.059\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(640, 64), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.754 0.052\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(640, 128), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.746 0.055\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(640, 256), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.741 0.067\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(1280, 2), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.526 0.067\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(1280, 8), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.573 0.12\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(1280, 12), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.584 0.117\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(1280, 24), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.56 0.105\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(1280, 32), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.633 0.122\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(1280, 64), max_iter=3000,\n",
      "              n_iter_no_change=40) 0.702 0.082\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(1280, 128),\n",
      "              max_iter=3000, n_iter_no_change=40) 0.731 0.075\n",
      "MLPClassifier(early_stopping=True, hidden_layer_sizes=(1280, 256),\n",
      "              max_iter=3000, n_iter_no_change=40) 0.734 0.076\n"
     ]
    }
   ],
   "source": [
    "# MLP two layer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "hidden_layers_1 = [12,24,32,64,128,256,320,640,1280]\n",
    "hidden_layers_2 = [2,8,12,24,32,64,128,256]\n",
    "acc_cv_mean_collection = []\n",
    "for i in hidden_layers_1:\n",
    "    for j in hidden_layers_2:\n",
    "        acc_cv_collection = []\n",
    "        clf = MLPClassifier(hidden_layer_sizes=(i,j),early_stopping = True,n_iter_no_change= 40,  max_iter = 3000)  # need to tune the hyperparameters\n",
    "        from sklearn.model_selection import cross_val_score, KFold, StratifiedKFold\n",
    "        skf = StratifiedKFold(n_splits=10)\n",
    "        for train, test in skf.split(X_train_whole, y_train_whole):\n",
    "            X_train, X_valid, y_train, y_valid = np.take(X_train_whole, train.tolist(), axis=0), np.take(X_train_whole,\n",
    "                                                                                                                    test.tolist(),\n",
    "                                                                                                                    axis=0), np.take(\n",
    "            y_train_whole, train.tolist(), axis=0), np.take(y_train_whole, test.tolist(), axis=0)\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_valid_pred = clf.predict(X_valid)\n",
    "            acc_cv = balanced_accuracy_score(y_valid, y_valid_pred)\n",
    "            acc_cv_collection.append(acc_cv)\n",
    "        acc_cv_mean_collection.append(round(statistics.mean(acc_cv_collection),3))\n",
    "        print(clf,round(statistics.mean(acc_cv_collection),3), round(statistics.stdev(acc_cv_collection),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f4Ru7iocM6aE",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### model development with best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "AQbu1XxtNFUG",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import statistics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Ah-bSWvcM-86",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "494dc713-5ffa-414e-f806-c9840012d1a0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.736 ± 0.029\n",
      "0.67 ± 0.051\n",
      "0.803 ± 0.036\n",
      "0.473 ± 0.058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xjding/anaconda3/envs/PLM4ACE/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# logistic regression for final test \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# result collection list\n",
    "ACC_collecton = []\n",
    "BACC_collecton = []\n",
    "Sn_collecton = []\n",
    "Sp_collecton = []\n",
    "MCC_collecton = []\n",
    "for i in range(10):\n",
    "    # dataset splitting\n",
    "    X_train_whole, X_ind_test, y_train_whole, y_ind_test =  train_test_split( X_new, y_new, test_size=0.2, random_state=i)\n",
    "    # clf = LogisticRegression(penalty= 'none', C=i, max_iter = 2000)\n",
    "    clf = LogisticRegression(C=50, max_iter=5000)\n",
    "    clf.fit(X_train_whole,y_train_whole)# fitting model \n",
    "    y_pred = clf.predict(X_ind_test)    # predict results\n",
    "    y_true = y_ind_test                 # asign values for confusiong matrix calculation\n",
    "    TP, FP, FN, TN = confusion_matrix(y_true, y_pred).ravel() # shape [ [True-Positive, False-positive], [False-negative, True-negative] ]\n",
    "    Sn_collecton.append(TP/(TP+FN))\n",
    "    Sp_collecton.append(TN/(TN+FP))\n",
    "    MCC = (TP*TN-FP*FN)/math.pow(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),0.5)\n",
    "    MCC_collecton.append(MCC)\n",
    "    BACC_collecton.append(0.5*TP/(TP+FN)+0.5*TN/(TN+FP))\n",
    "    \n",
    "print(round(statistics.mean(BACC_collecton),3),'±',round(statistics.stdev(BACC_collecton),3))\n",
    "print(round(statistics.mean(Sn_collecton),3),'±',round(statistics.stdev(Sn_collecton),3))\n",
    "print(round(statistics.mean(Sp_collecton),3),'±',round(statistics.stdev(Sp_collecton),3))\n",
    "print(round(statistics.mean(MCC_collecton),3),'±',round(statistics.stdev(MCC_collecton),3))\n",
    "# print(round(mean(AUC_collecton),3),'±',round(stdev(AUC_collecton),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "31Axqp_POnjm",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "c4da785e-e5da-443f-a640-1ddfd0676ed4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.778 ± 0.03\n",
      "0.766 ± 0.067\n",
      "0.79 ± 0.036\n",
      "0.522 ± 0.047\n"
     ]
    }
   ],
   "source": [
    "# random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# result collection list\n",
    "ACC_collecton = []\n",
    "BACC_collecton = []\n",
    "Sn_collecton = []\n",
    "Sp_collecton = []\n",
    "MCC_collecton = []\n",
    "for i in range(10):\n",
    "    # dataset splitting\n",
    "    X_train_whole, X_ind_test, y_train_whole, y_ind_test =  train_test_split( X_new, y_new, test_size=0.2, random_state=i)\n",
    "    clf = RandomForestClassifier(max_depth=4, n_estimators=480)\n",
    "    clf.fit(X_train_whole,y_train_whole)# fitting model \n",
    "    y_pred = clf.predict(X_ind_test)    # predict results\n",
    "    y_true = y_ind_test                 # asign values for confusiong matrix calculation\n",
    "    TP, FP, FN, TN = confusion_matrix(y_true, y_pred).ravel() # shape [ [True-Positive, False-positive], [False-negative, True-negative] ]\n",
    "    Sn_collecton.append(TP/(TP+FN))\n",
    "    Sp_collecton.append(TN/(TN+FP))\n",
    "    MCC = (TP*TN-FP*FN)/math.pow(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),0.5)\n",
    "    MCC_collecton.append(MCC)\n",
    "    BACC_collecton.append(0.5*TP/(TP+FN)+0.5*TN/(TN+FP))\n",
    "    \n",
    "print(round(statistics.mean(BACC_collecton),3),'±',round(statistics.stdev(BACC_collecton),3))\n",
    "print(round(statistics.mean(Sn_collecton),3),'±',round(statistics.stdev(Sn_collecton),3))\n",
    "print(round(statistics.mean(Sp_collecton),3),'±',round(statistics.stdev(Sp_collecton),3))\n",
    "print(round(statistics.mean(MCC_collecton),3),'±',round(statistics.stdev(MCC_collecton),3))\n",
    "# print(round(mean(AUC_collecton),3),'±',round(stdev(AUC_collecton),3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Rg3bw9xjOsJh",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "27e85d23-c093-4640-e663-7658d38496a2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.716 ± 0.023\n",
      "0.636 ± 0.039\n",
      "0.796 ± 0.028\n",
      "0.437 ± 0.046\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# result collection list\n",
    "ACC_collecton = []\n",
    "BACC_collecton = []\n",
    "Sn_collecton = []\n",
    "Sp_collecton = []\n",
    "MCC_collecton = []\n",
    "for i in range(10):\n",
    "    # dataset splitting\n",
    "    X_train_whole, X_ind_test, y_train_whole, y_ind_test =  train_test_split( X_new, y_new, test_size=0.2, random_state=i)\n",
    "    clf = KNeighborsClassifier(leaf_size=80, n_neighbors=3, weights='distance')\n",
    "    clf.fit(X_train_whole,y_train_whole)# fitting model \n",
    "    y_pred = clf.predict(X_ind_test)    # predict results\n",
    "    y_true = y_ind_test                 # asign values for confusiong matrix calculation\n",
    "    TP, FP, FN, TN = confusion_matrix(y_true, y_pred).ravel() # shape [ [True-Positive, False-positive], [False-negative, True-negative] ]\n",
    "    Sn_collecton.append(TP/(TP+FN))\n",
    "    Sp_collecton.append(TN/(TN+FP))\n",
    "    MCC = (TP*TN-FP*FN)/math.pow(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),0.5)\n",
    "    MCC_collecton.append(MCC)\n",
    "    BACC_collecton.append(0.5*TP/(TP+FN)+0.5*TN/(TN+FP))\n",
    "\n",
    "print(round(statistics.mean(BACC_collecton),3),'±',round(statistics.stdev(BACC_collecton),3))\n",
    "print(round(statistics.mean(Sn_collecton),3),'±',round(statistics.stdev(Sn_collecton),3))\n",
    "print(round(statistics.mean(Sp_collecton),3),'±',round(statistics.stdev(Sp_collecton),3))\n",
    "print(round(statistics.mean(MCC_collecton),3),'±',round(statistics.stdev(MCC_collecton),3))\n",
    "# print(round(mean(AUC_collecton),3),'±',round(stdev(AUC_collecton),3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "kGAR7eT2OmvK",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "8a072cc3-f889-4448-b036-5e2292c90473",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.765 ± 0.03\n",
      "0.712 ± 0.049\n",
      "0.817 ± 0.039\n",
      "0.525 ± 0.062\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "from sklearn.svm import SVC\n",
    "# result collection list\n",
    "ACC_collecton = []\n",
    "BACC_collecton = []\n",
    "Sn_collecton = []\n",
    "Sp_collecton = []\n",
    "MCC_collecton = []\n",
    "for i in range(10):\n",
    "    # dataset splitting\n",
    "    X_train_whole, X_ind_test, y_train_whole, y_ind_test =  train_test_split( X_new, y_new, test_size=0.2, random_state=i)\n",
    "    clf = SVC(C=5, degree=5)\n",
    "    clf.fit(X_train_whole,y_train_whole)# fitting model \n",
    "    y_pred = clf.predict(X_ind_test)    # predict results\n",
    "    y_true = y_ind_test                 # asign values for confusiong matrix calculation\n",
    "    TP, FP, FN, TN = confusion_matrix(y_true, y_pred).ravel() # shape [ [True-Positive, False-positive], [False-negative, True-negative] ]\n",
    "    Sn_collecton.append(TP/(TP+FN))\n",
    "    Sp_collecton.append(TN/(TN+FP))\n",
    "    MCC = (TP*TN-FP*FN)/math.pow(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),0.5)\n",
    "    MCC_collecton.append(MCC)\n",
    "    BACC_collecton.append(0.5*TP/(TP+FN)+0.5*TN/(TN+FP))\n",
    "    \n",
    "print(round(statistics.mean(BACC_collecton),3),'±',round(statistics.stdev(BACC_collecton),3))\n",
    "print(round(statistics.mean(Sn_collecton),3),'±',round(statistics.stdev(Sn_collecton),3))\n",
    "print(round(statistics.mean(Sp_collecton),3),'±',round(statistics.stdev(Sp_collecton),3))\n",
    "print(round(statistics.mean(MCC_collecton),3),'±',round(statistics.stdev(MCC_collecton),3))\n",
    "# print(round(mean(AUC_collecton),3),'±',round(stdev(AUC_collecton),3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.737 ± 0.036\n",
      "0.695 ± 0.067\n",
      "0.779 ± 0.054\n",
      "0.447 ± 0.104\n"
     ]
    }
   ],
   "source": [
    "# MLP\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "# result collection list\n",
    "ACC_collecton = []\n",
    "BACC_collecton = []\n",
    "Sn_collecton = []\n",
    "Sp_collecton = []\n",
    "MCC_collecton = []\n",
    "for i in range(10):\n",
    "    # dataset splitting\n",
    "    X_train_whole, X_ind_test, y_train_whole, y_ind_test =  train_test_split( X_new, y_new, test_size=0.2, random_state=i)\n",
    "    clf = MLPClassifier(early_stopping=True, hidden_layer_sizes=(640, 32), max_iter=3000,\n",
    "              n_iter_no_change=40)\n",
    "    clf.fit(X_train_whole,y_train_whole)# fitting model\n",
    "    y_pred = clf.predict(X_ind_test)    # predict results\n",
    "    y_true = y_ind_test                 # asign values for confusiong matrix calculation\n",
    "    TP, FP, FN, TN = confusion_matrix(y_true, y_pred).ravel() # shape [ [True-Positive, False-positive], [False-negative, True-negative] ]\n",
    "    Sn_collecton.append(TP/(TP+FN))\n",
    "    Sp_collecton.append(TN/(TN+FP))\n",
    "    MCC = (TP*TN-FP*FN)/math.pow(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),0.5)\n",
    "    MCC_collecton.append(MCC)\n",
    "    BACC_collecton.append(0.5*TP/(TP+FN)+0.5*TN/(TN+FP))\n",
    "\n",
    "print(round(statistics.mean(BACC_collecton),3),'±',round(statistics.stdev(BACC_collecton),3))\n",
    "print(round(statistics.mean(Sn_collecton),3),'±',round(statistics.stdev(Sn_collecton),3))\n",
    "print(round(statistics.mean(Sp_collecton),3),'±',round(statistics.stdev(Sp_collecton),3))\n",
    "print(round(statistics.mean(MCC_collecton),3),'±',round(statistics.stdev(MCC_collecton),3))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "95NTckuFZZzm",
    "m91cA0H5w_eY",
    "RddxugbsdR1Y",
    "9EzJGXsk1w-Z",
    "dN8Xh24_RHtp",
    "2eOgwG39J15b",
    "EzMyShvqxxAy",
    "lDxnvWKb1rTP",
    "5P1fK2FJApwf",
    "YjMK3qEHAvLV",
    "Cp1Han6zB1vU",
    "qoJpjw-uCihR",
    "XUm2yu6cCqi7",
    "pIZ278ZDOwmA",
    "f4Ru7iocM6aE",
    "XmntS7leeBR3",
    "H7i852E3TUgi",
    "hOABwh18TfeX",
    "U3Fagh9Iw83q"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}